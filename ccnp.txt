Chapter 1: Fundamentals Review
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 1 Objectives
This chapter covers the following basic switching topics as a review to CCNA and serves as a teaser for topics covered later in chapter:
Hubs and switches
Bridges and switches
Switches of today
Broadcast domains
MAC addresses
The basic Ethernet frame format
Basic switching function
VLANs
The Spanning Tree Protocol
Trunking
Port channels
Multilayer switching (MLS)

Fundamentals Review
Hubs and Switches
Hubs are archaic, and the terminology should be avoided. Even the simplest multiport Ethernet devices for the home are switches.
In review, hubs died off as a product because they are shared-bandwidth devices. 
Switches introduced dedicated bandwidth. A hub allows multiple devices to be connected to the same network segment. The devices on that segment share the bandwidth with each other.
A switch allows multiple devices to be connected to the same network, just like a hub does, but this is where the similarity ends. 
A switch allows each connected device to have dedicated bandwidth instead of shared bandwidth. 
Switches also support additional capabilities beyond what hubs support.
Bridges and Switches
A basic switch is considered a Layer 2 device. When we use the word layer , we are referring to the seven-layer OSI reference model. 
A switch does not just pass electrical signals along, like a hub does; instead, it assembles the signals into a frame (Layer 2), and then decides what to do with the frame. 
A switch determines what to do with a frame by borrowing an algorithm from a previously common networking device: a transparent bridge. 
Logically, a switch acts just like a transparent bridge would, but it can handle frames much faster than a transparent bridge could 
Once a switch decides where the frame should be sent, it passes the frame out the appropriate port (or ports). You can think of a switch as a device creating instantaneous connections between various ports, on a frame-by-frame basis.
Switches of Today
Today’s switches have evolved beyond just switching frames. Most modern switches can actually route traffic. In addition, switches can prioritize traffic, support no downtime through redundancy, and provide convergence services around IP telephony and wireless networks.
Application intelligence
This helps networks recognize many types of applications and secure and prioritize those applications to provide the best user experience.
Unified network services
Combining the best elements of wireless and wired networking allows you to consistently connect to any resource or person with any device. 10 Gigabit Ethernet technology and Power over Ethernet (PoE) technology support new applications and devices.
Nonstop communications
Features such as redundant hardware, and nonstop forwarding and stateful switchover (NSF/SSO) technology support more-reliable connections.
Integrated security
LAN switches provide the first line of defense against internal network attacks and prevent unauthorized intrusion.
Operational manageability
To more easily manage the network, IT staff must be able to remotely configure and monitor network devices from a central location.
Broadcast Domains
A broadcast domain is a set of network devices that receive broadcast frames originating from any device within the group. 
Routers typically bound broadcast domains because routers do not forward broadcast frames. 
VLANs are an example of broadcast domain. 
Broadcast domains are generally limited to a specific Layer 2 segment that contains a single IP subnet. 
MAC Addresses
MAC addresses are standardized data link layer addresses that are required for every port or device that connects to a LAN. 
Other devices in the network use these addresses to locate specific ports in the network and to create and update routing tables and data structures. 
MAC addresses are 6 bytes long and are controlled by the IEEE. 
The Basic Ethernet Frame Format
The Basic Ethernet Frame Format
Preamble (PRE)
Consists of 7 bytes. The PRE is an alternating pattern of 1s and 0s that tells receiving stations that a frame is coming, and that provides a means of synchronization 
Start-of-frame delimiter (SOF)
Consists of 1 byte. The SOF is an alternating pattern of 1s and 0s, ending with two consecutive 1 bits, indicating that the next bit is the leftmost bit in the leftmost byte of the destination address.
 Destination address (DA)
Consists of 6 bytes. The DA field identifies which station(s) should receive the frame. 
Source addresses (SA)
Consists of 6 bytes. The SA field identifies the sending station.
The Basic Ethernet Frame Format
Length/Type
Consists of 2 bytes. This field indicates either the number of MAC-client data bytes that are contained in the data field of the frame, or the frame type ID if the frame is assembled using an optional format. 
Data
Is a sequence of n bytes of any value, where n is less than or equal to 1500. 
Note that jumbo frames up to 9000 bytes are supported on the current-generation Cisco Catalyst switches.
Frame check sequence (FCS)
Consists of 4 bytes. This sequence contains a 32-bit cyclic redundancy check (CRC) value, which is created by the sending MAC and is recalculated by the receiving MAC to check for damaged frames. The FCS is generated over the DA, SA, Length/Type, and Data fields.
Basic Switching Function
In brief, the basic switching function at Layer 2 adheres to these rules for determining forwarding responsibility:
If the destination MAC address is found in the CAM table, the switch sends the frame out the port that is associated with that destination MAC address in the CAM table. This process is called forwarding .
If the associated port to send the frame out is the same port that the frame originally came in on, there is no need to send the frame back out that same port, and the frame is ignored. This process is called filtering .
If the destination MAC address is not in the CAM table (that is, unknown unicast), the switch sends the frame out all other ports that are in the same VLAN as the received frame. This is called flooding . It does not flood the frame out the same port on which the frame was received.
If the destination MAC address of the received frame is the broadcast address (FFFF.FFFF.FFFF), the frame is sent out all ports that are in the same VLAN as the received frame. This is also called flooding . 
VLANs
Because the switch decides on a frame-by-frame basis which ports exchange data, it is a natural extension to put logic inside the switch to allow it to choose ports for special groupings. This grouping of ports is called a virtual local-area network (VLAN). 
The switch makes sure that traffic from one group of ports never gets sent to other groups of ports (which would be routing). 
These port groups (VLANs) can each be considered an individual LAN segment. 
VLANs are also described as broadcast domains. This is because of the transparent bridging algorithm, which says that broadcast packets (packets destined for the all devices address) be sent out all ports that are in the same group (that is, in the same VLAN).
All ports that are in the same VLAN are also in the same broadcast domain.
The Spanning Tree Protocol
As discussed previously, the switch forwarding algorithm floods unknown and broadcast frames out of all the ports that are in the same VLAN as the received frame. This causes a potential problem. If the network devices that run this algorithm are connected together in a physical loop, flooded frames (like broadcasts) are passed from switch to switch, around and around the loop, forever. 
There is a benefit to a physical loop in your network: It can provide redundancy. If one link fails, there is still another way for the traffic to reach its destination. To allow the benefits derived from redundancy, without breaking the network because of flooding, a protocol called the Spanning Tree Protocol (STP) was created. 
Spanning tree was standardized in the IEEE 802.1D specification.
The purpose of STP is to identify and temporarily block the loops in a network segment or VLAN. The switches run STP, which involves electing a root bridge or switch.
The other switches measure their distance from the root switch. If there is more than one way to get to the root switch, there is a loop. The switches follow the algorithm to determine which ports must be blocked to break the loop. 
STP is dynamic; if a link in the segment fails, ports that were originally blocking can possibly be changed to forwarding mode.
Trunking
Trunking is a mechanism that is most often used to allow multiple VLANs to function independently across multiple switches. 
Routers and servers can use trunking, as well, which allows them to live simultaneously on multiple VLANs. 
If your network only has one VLAN in it, you might never need trunking; but if your network has more than one VLAN, you probably want to take advantage of the benefits of trunking.
A port on a switch normally belongs to only one VLAN; any traffic received or sent on this port is assumed to belong to the configured VLAN. 
A trunk port, however, is a port that can be configured to send and receive traffic for many VLANs. 
It accomplishes this when it attaches VLAN information to each frame, a process called tagging the frame.
Also, trunking must be active on both sides of the link; the other side must expect frames that include VLAN information for proper communication to occur. 
Port Channels
Utilizing port channels (EtherChannels) is a technique that is used when you have multiple connections to the “same device”. 
Rather than each link functioning independently, port channels group the ports together to work as one unit. Port channels distribute traffic across all the links and provide redundancy if one or more links fail. 
Port channel settings must be the same on both sides of the links involved in the channel. 
Normally, spanning tree would block all of these parallel connections between devices because they are loops, but port channels run underneath spanning tree, so that spanning tree thinks all the ports within a given port channel are only a single port. 
Multilayer Switching
Multilayer switching (MLS) is the ability of a switch to forward frames based on information in the Layer 3 and sometimes Layer 4 header. Almost all Cisco Catalyst switches model 3500 or later support MLS. MLS is becoming a legacy term due to the wide support.
The most important aspect to MLS is recognizing that switches can route or switch frames at wire-rate speeds using specialized hardware. This effectively bundles the routing function into the switch and is specifically useful for routing between VLANs in the core of the network. 
Chapter 1 Summary
Hubs and switches
Bridges and switches
Switches of today
Broadcast domains
MAC addresses
The basic Ethernet frame format
Basic switching function
VLANs
The Spanning Tree Protocol
Trunking
Port channels
Multilayer switching (MLS)
Chapter 1 Labs
CCNPv7.1 SWITCH Lab1 BASELINE STUDENT

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva
Chapter 2: Network Design Fundamentals
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 2 Objectives
Campus network structure
Introduction to Cisco switches and their associated architecture
Campus Network Structure
Hierarchical Network Design
Flat Network Design 
A flat enterprise campus network is where all PCs, servers, and printers are connected to each other using Layer 2 switches. 
A flat network does not use subnets for any design purposes. In addition, all devices on this subnet are in the same broadcast domain, and broadcasts will be flooded to all attached network devices. 
Wasting bandwidth and computational resources.
Flat networks do not scale to meet the needs of most enterprise networks or of many small and medium-size businesses.
Hierarchical Network Design
Hierarchical models for network design allow you to design any networks in layers. 
Leveraging the hierarchical model also simplifies campus network design by allowing focus at different layers that build on each other. 
The layers of the hierarchical model are divided into specific functions categorized as core, distribution, and access layers. 
This categorization provides for modular and flexible design, with the ability to grow and scale the design without major modifications or reworks.
Hierarchical Model Layers
Access layer
The access layer is used to grant the user access to network applications and functions. In a campus network, the access layer generally incorporates switched LAN devices with ports that provide connectivity to workstations, IP phones, access points, and printers. In a WAN environment, the access layer for teleworkers or remote sites may provide access to the corporate network across WAN technologies.
Distribution layer
The distribution layer aggregates the access layer switches wiring closets, floors, or other physical domain by leveraging module or Layer 3 switches.
Similarly, a distribution layer may aggregate the WAN connections at the edge of the campus and provides policy-based connectivity.
Core layer (also referred to as the backbone)
The core layer is a high-speed backbone, which is designed to switch packets as fast as possible. In most campus networks, the core layer has routing capabilities. 
Because the core is critical for connectivity, it must provide a high level of availability and adapt to changes quickly. It also provides for dynamic scalability to accommodate growth and fast convergence in the event of a failure.
Access Layer
Describes the logical grouping of the switches that interconnect end devices such as PCs, printers, cameras, and so on. 
It is also the place where devices that extend the network out one more level are attached. 
Two such prime examples are IP phones and wireless APs, both of which extend the connectivity out one more layer from the actual campus access switch.
Access Layer Capabilities
High availability
The access layer supports high availability via default gateway redundancy using dual connections from access switches to redundant distribution layer switches when there is no routing in the access layer. This mechanism behind default gateway redundancy is referred to as first-hop redundancy protocol (FHRP). 
Convergence
The access layer generally supports inline Power over Ethernet (PoE) for IP telephony, thin clients, and wireless access points (APs). 
In addition, the access layers allow support for converged features that enable optimal software configuration of IP phones and wireless APs, as well.
Security
The access layer also provides services for additional security against unauthorized access to the network by using tools such as port security, quality of service (QoS), Dynamic Host Configuration Protocol (DHCP) snooping, dynamic ARP inspection (DAI), and IP Source Guard.
Distribution Layer
The distribution layer in the campus design has a unique role in which it acts as a services and control boundary between the access layer and the core.
Availability, fast path recovery, load balancing, and QoS are all important considerations at the distribution layer. 
Generally, high availability is provided through Layer 3 redundant paths from the distribution layer to the core, and either Layer 2 or Layer 3 redundant paths from the access layer to the distribution layer. 
Distribution Layer
With a Layer 2 design in the access layer, the distribution layer generally serves as a routing boundary between the access and core layer by terminating VLANs. 
The distribution layer may perform tasks such as controlled routing decision making and filtering to implement policy-based connectivity, security, and QoS. 
These features allow for tighter control of traffic through the campus network.
To improve routing protocol performance further, the distribution layer is generally designed to summarize routes from the access layer. 
In addition, the distribution layer optionally provides default gateway redundancy by using a first-hop routing protocol (FHRP) such as HSRP, GLBP, or VRRP. 
Distribution Layer Functions
Provides high availability and equal-cost load sharing by interconnecting the core and access layer via at least dual paths
Generally terminates a Layer 2 domain of a VLAN
Routes traffic from terminated VLANs to other VLANs and to the core
Summarizes access layer routes
Implements policy-based connectivity such as traffic filtering, QoS, and security
Provides for an FHRP
Core Layer (Backbone)
From a design point-of-view, the campus core is in some ways the simplest yet most critical part of the campus. 
It provides a limited set of services and is designed to be highly available and requires 100 percent uptime. 
In large enterprises, the core of the network must operate as a nonstop, always-available service. 

Core Layer (Backbone)
The key design objectives for the campus core are based on providing the appropriate level of redundancy to allow for near-immediate data-flow recovery in the event of the failure of any component (switch, supervisor, line card, or fiber interconnect, power, and so on). 
The network design must also permit the occasional, but necessary, hardware and software upgrade or change to be made without disrupting any network applications. 
The core of the network should not implement any complex policy services, nor should it have any directly attached user or server connections. 
The core should also have the minimal control plane configuration that is combined with highly available devices that are configured with the correct amount of physical redundancy to provide for this nonstop service capability.
Core Layer (Backbone)
From an enterprise architecture point-of-view, the campus core is the backbone that binds together all the elements of the campus architecture to include the WAN, the data center, and so on. In other words, the core layer is the part of the network that provides for connectivity between end devices, computing, and data storage services that are located within the data center, in addition to other areas and services within the network.
Core Layer Functions
Aggregates the campus networks and provides interconnectivity to the data center, the WAN, and other remote networks
Requires high availability, resiliency, and the ability to make software and hardware upgrades without interruption
Designed without direct connectivity to servers, PCs, access points, and so on
Requires core routing capability
Architected for future growth and scalability
Leverages Cisco platforms that support hardware redundancy such as the Catalyst 4500 and the Catalyst 6800
Core Layer Interconnecting with the Enterprise Network
Layer 3 in the Access Layer
Because of the reduced cost and a few inherit benefits, Layer 3 switching in the access layer has become more common over typical Layer 2 switching in the access layer. 
Using Layer 3 switching or traditional Layer 2 switching in the access layer has benefits and drawbacks. 
Layer 3 in the Access Layer
Benefits
Using a design that leverages Layer 3 switching to the access layer VLANs scales better than Layer 2 switching designs because VLANs get terminated on the access layer devices.
Specifically, the links between the distribution and access layer switches are routed links; all access and distribution devices would participate in the routing scheme.
The Layer 2-only access design is a traditional, slightly cheaper solution, but it suffers from optimal use of links between access and distribution due to spanning tree
Drawbacks
Layer 3 designs introduce the challenge of how to separate traffic. 
Layer 3 designs also require careful planning with respect to IP addressing. 
A VLAN on one Layer 3 access device cannot be on another access layer switch in a different part of your network because each VLAN is globally significant. 
Traditionally, mobility of devices is limited in the campus network of the enterprise in Layer 3 access layer networks. without using an advanced mobility networking features .
The Need for a Core Layer
In a campus network contained with a few buildings or a similar physical infrastructure, collapsing the core into the distribution layer switches may save on initial cost because an entire layer of switches is not needed. 

The Need for a Core Layer
Despite a possible lower cost to the initial build, this design is difficult to scale. In addition, cabling requirements increase dramatically with each new building because of the need for full-mesh connectivity to all the distribution switches. The routing complexity also increases as new buildings are added because additional routing peers are needed.

Types of Cisco Switches
Cisco designs the Catalyst switches for campus networks and Nexus switches for data centers. The context of CCNP will focus mostly on Catalyst switches.
Comparing Layer 2 and Multilayer Switches
L2 switches make decisions about forwarding frames based on the destination MAC addresses found within the frame.
When a switch receives in store-n-forward mode, the frame is checked for errors, and frames with a valid cyclic redundancy check (CRC) are regenerated and transmitted. 
Some models of switches, mostly Nexus switches, opt to switch frames based only on reading the Layer 2 information and bypassing the CRC check. 
This bypass, referred to as cut-through switching, lowers the latency of the frame transmission as the entire frame is not stored before transmission to another port. 
Lower switching latency is beneficial for low-latency applications such as algorithm trading programs found in the data center. The assumption is that the end device network interface card (NIC) or an upper-level protocol will eventually discard the bad frame. 
Most Catalyst switches are store-n-forward.
MAC Address Forwarding
Where should the frame be forwarded?
Are there restrictions preventing the forwarding of the frame?
Is there any prioritization or marking that needs to be applied to the frame?
Layer 2 Switch Operation
Layer 2 forwarding table
The Layer 2 forwarding table, also called the MAC table , contains information about where to forward the frame. Specifically, it contains MAC addresses and destination ports. The switches reference the destination MAC address of the incoming frame in the MAC table and forward the frames to the destination ports specified in the table. If the MAC address is not found, the frame is flooded through all ports in the same VLAN.
ACLs
Access control lists (ACLs) do not only apply to routers. Switches can also apply ACLs based on MAC and IP addresses. Generally only higher-end switches support ACLs based on both MAC and IP addresses, whereas Layer 2 switches support ACLs only with MAC addresses.
QoS
Incoming frames can be classified according to QoS parameters. Traffic can then be marked, prioritized, or rate-limited.
Layer 2 Switch Operation
CAM and TCAM are extremely fast access and allow for line-rate switching performance. CAM supports only two results: 0 or 1. 
Therefore, CAM is useful for Layer 2 forwarding tables.
TCAM provides three results: 0, 1, and don’t care. TCAM is most useful for building tables for searching on longest matches, such as IP routing tables organized by IP prefixes.
 The TCAM table stores ACL, QoS, and other information generally associated with upper-layer processing. As a result of using TCAM, applying ACLs does not affect the performance of the switch.
Layer 3 (Multilayer) Switch Operation
Multilayer switches not only perform Layer 2 switching but also forward frames based on Layer 3 and 4 information.
Multilayer switches not only combine the functions of a switch and a router but also add a flow cache component.
Commands for Viewing and Editing Catalyst Switch MAC Address Tables
Distributed Hardware Forwarding
Network devices contain at least three planes of operation:
Management plane
Control plane
Forwarding plane
Distributed Hardware Forwarding
The management plane is responsible for the network management, such as SSH access and SNMP, and may operate over an out-of-band (OOB) port. 
The control plane is responsible for protocols and routing decisions, and the forwarding plane is responsible for the actual routing (or switching) of most packets.
Multilayer switches must achieve high performance at line rate across a large number of ports. To do so, multilayer switches deploy independent control and forwarding planes.
The control plane will program the forwarding plane on how to route packets. 
Multilayer switches may also employ multiple forwarding planes. For example, a Catalyst 6800 uses forwarding planes on each line module, with a central control plane on the supervisor module.
To continue the example of the Catalyst 6800, each line module includes a microcoded processor that handles all packet forwarding. 
For the control plane on the supervisor to communicate with the line module, a control layer communication protocol exists.
Cisco Switching Methods
A Cisco IOS-based routers uses one of three methods to forward packets: 
Process Switching
Process switching is the slowest form of routing because the processor must route and rewrite using software.
Fast Switching
Is a faster method by which the first packet in a flow is routed and rewritten by a route processor using software, and each subsequent packet is then handled by hardware. 
Cisco Express Forwarding (CEF)
The CEF method uses hardware forwarding tables for most common traffic flows, with only a few exceptions. If you use CEF, the route processor spends its cycles mostly on other tasks.
Cisco Switching Methods
The architecture of the Cisco Catalyst and Nexus switches both focus primarily on the Cisco router equivalents of CEF. 
The absolute last-resort switching method for Cisco Catalyst or Nexus switches is process switching. 
The route processors of these switches were never designed to switch or route packets, and by doing so, this will have an adverse effect on performance. 
Fortunately, the default behavior of these switches is to use fast switching or CEF, and process switching occurs only when necessary.
Cisco Switching Methods
With Cisco Catalyst switching terminology, fast switching is referred to as route caching , and the application of CEF with distributed hardware forwarding is referred to as topology-based switching.
As a review, the following list summarizes route caching and topology-based forwarding on Cisco Catalyst switches:
Route caching
Also known as flow-based or demand-based switching , route caching describes a Layer 3 route cache that is built within the hardware functions as the switch detects traffic flow into the switch. 
Topology-based switching
Information from the routing table is used to populate the route cache, regardless of traffic flow. The populated route cache is the FIB,and CEF is the facility that builds the FIB. 
Route Caching
The first packet in a stream is switched in software by the route processor, because no cache entry exists yet for the new flow.
Topology-Based Switching
CEF uses information in the routing table to populate a route cache (known as an FIB), without traffic flows being necessary to initiate the caching process.
In addition, CEF adds enhanced support for parallel paths and thus optimizes load balancing at the IP layer. 
In most current-generation Catalyst switches, CEF supports both load balancing based on source IP address and destination IP address combination and source and destination IP plus TCP/UDP port number.
Hardware Forward Details
The actual Layer 3 switching of packets occurs at two possible different locations on Catalyst switches. 
These possible locations are in a centralized manner, such as on a supervisor module, or in distributed fashion, where switching occurs on individual line modules. 
These methods are referred to as centralized switching and distributed switching , respectively.
The Catalyst 6500 was a perfect example where there was an option to centralize switch everything on the supervisor or place specific hardware versions of line modules in the chassis to gain distributed switching capability.
The benefits of centralized switching include lower hardware cost and lower complexity.
For scaling and large enterprise core networks, distributed switching is optimal. Most small form-factor switches leverage centralized switching.
Chapter 2 Summary
Flat Layer 2 networks are extremely limited in scale and in most cases will only scale to 10 to 20 end users before adverse conditions may occur.
Despite its age, the hierarchical model continues to be a key design fundamental of any network design, including campus network designs.
The hierarchical model consists of an access, distribution, and core layer, thus allowing for scalability and growth of a campus network in a seamless manner.
The different models of Cisco Catalyst switches provide for a range of capabilities depending on need and placement within the hierarchical model.
Cisco Catalyst switches leverage CAM for Layer 2 forwarding tables and TCAM for Layer 3 forwarding tables to achieve line-rate performance.
Cisco Catalyst switches leverage CEF (topology-based switching) for routing, utilizing a distributed hardware forwarding model that is centralized or distributed per line card .
Chapter 2 Labs
None

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva1

Chapter 3: Campus Network Architecture
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 3 Objectives
Implementing VLANs and trunks in campus switched architecture
Understanding the concept of VTP and its limitation and configurations
Implementing and configuring EtherChannel
Implementing VLANs and Trunks in CampusEnvironment
Implementing VLANs and Trunks in CampusEnvironment
Within the switched internetwork, VLANs provide segmentation and organizational flexibility. 
VLANs help administrators to have the end node or workstations group that are segmented logically by functions, project teams, and applications, without regard to the physical location of the users. 
VLANs allow you to implement access and security policies to particular groups of users and limit the broadcast domain.
The voice VLAN feature enables access ports to carry IP voice traffic from an IP phone. Because the sound quality of an IP phone call can deteriorate if the data is unevenly sent, the switch supports quality of service (QoS).
VLAN Overview
VLAN Segmentation
Larger flat networks generally consist of many end devices in which broadcasts and unknown unicast packets are flooded on all ports in the network. 
One advantage of using VLANs is the capability to segment the Layer 2 broadcast domain.  All devices in a VLAN are members of the same broadcast domain. If an end device transmits a Layer 2 broadcast, all other members of the VLAN receive the broadcast. 
Switches filter the broadcast from all the ports or devices that are not part of the same VLAN.
In a campus design, a network administrator can design a campus network with one of two models: 
End-to-End VLANs
Local VLANs.
Each model has its own advantages and disadvantages. 
End-to-End VLANs
End-to-End VLAN refers to a single VLAN that is associated with switch ports widely dispersed throughout an enterprise network on multiple switches.
End-to-End VLAN Model Characteristics
Each VLAN is dispersed geographically throughout the network.
Users are grouped into each VLAN regardless of the physical location.
As a user moves throughout a campus, the VLAN membership of that user remains the same, regardless of the physical switch to which this user attaches.
Users are typically associated with a given VLAN for network management reasons. This is why they are kept in the same VLAN, therefore the same group, as they move through the campus.
All devices on a given VLAN typically have addresses on the same IP subnet.
Switches commonly operate in a server/client VTP mode.
Local VLANs
In a local VLAN model, all users of a set of geographically common switches are grouped into a single VLAN, regardless of the organizational function of those users.
Local VLAN Model Characteristics
The network administrator should create local VLANs with physical boundaries in mind rather than the job functions of the users on the end devices.
Generally, local VLANs exist between the access and distribution levels.
Traffic from a local VLAN is routed at the distribution and core levels to reach destinations on other networks.
Configure the VTP mode in transparent mode because VLANs on a given access switch should not be advertised to all other switches in the network, nor do they need to be manually created in any other switch VLAN databases.
A network that consists entirely of local VLANs can benefit from increased convergence times offered via routing protocols, instead of a spanning tree for Layer 2 networks. It is usually recommended to have one to three VLANs per access layer switch.
Comparison of End-to-End VLANs and Local VLANs
Reasons for implementing the end-to-end design:
Grouping users
Users can be grouped on a common IP segment, even though they are geographically dispersed. 
Security 
A VLAN can contain resources that should not be accessible to all users on the network, or there might be a reason to confine certain traffic to a particular VLAN.
Applying quality of service (QoS)
Traffic can be a higher- or lower-access priority to network resources from a given VLAN.
Comparison of End-to-End VLANs and Local VLANs
Reasons for implementing the end-to-end design (cont.):
Routing avoidance
If much of the VLAN user traffic is destined for devices on that same VLAN.
Special-purpose VLAN
Sometimes a VLAN is provisioned to carry a single type of traffic that must be dispersed throughout the campus (for example, multicast, voice, or visitor VLANs).
Poor design
For no clear purpose, users are placed in VLANs that span the campus or even span WANs. Sometimes when a network is already configured and running, organizations are hesitant to improve the design because of downtime or other political reasons.
Comparison of End-to-End VLANs and Local VLANs
Reasons for implementing the Local Vlan design: 
Deterministic traffic flow
The simple layout provides a predictable Layer 2 and Layer 3 traffic path. 
Active redundant paths
When implementing Per-VLAN Spanning Tree (PVST) or Multiple Spanning Tree (MST) because there is no loop, all links can be used to make use of the redundant paths.
High availability
Redundant paths exist at all infrastructure levels. 
Finite failure domain
If VLANs are local to a switch block, and the number of devices on each VLAN is kept small, failures at Layer 2 are confined to a small subset of users.
Scalable design
Following the enterprise campus architecture design, new access switches can be easily incorporated, and new submodules can be added when necessary.
Comparison of End-to-End VLANs and Local VLANs
End-to-End VLANs drawbacks:
Switch ports are provisioned for each user and associated with a given VLAN. Because users on an end-to-end VLAN can be anywhere in the network, all switches must be aware of that VLAN. This means that all switches carrying traffic for end-to-end VLANs are required to have those specific VLANs defined in each switch’s VLAN database.
Flooded traffic for the VLAN is, by default, passed to every switch even if it does not currently have any active ports in the particular end-to-end VLAN.
Troubleshooting devices on a campus with end-to-end VLANs can be challenging because the traffic for a single VLAN can traverse multiple switches in a large area of the campus, and that can easily cause potential spanning-tree problems.
Implementing a Trunk in a Campus Environment
A trunk is a point-to-point link that carries the traffic for multiple VLANs across a single physical link between the two switches or any two devices.
 Trunking is used to extend Layer 2 operations across an entire network.
Trunking Protocols
A special protocol is used to carry multiple VLANs over a single link between two devices.
There are two trunking technologies:
Inter-Switch Link (ISL): A Cisco proprietary trunking encapsulation
IEEE 802.1Q: An industry-standard trunking method
ISL Frame
802.1Q Frame
IEEE 802.1Q/802.1p advantages over ISL
802.1Q has smaller frame overhead than ISL. As a result, 802.1Q is more efficient than ISL, especially in the case of small frames. 802.1Q overhead is 4 bytes, whereas ISL is 30 bytes.
802.1Q is a widely supported industry standard protocol.
802.1Q has the support for 802.1p fields for QoS.

802.1Q tag
Inserted 802.1Q tag (4 bytes, detailed here)
EtherType(TPID): Set to 0x8100 to specify that the 802.1Q tag follows.
PRI: 3-bit 802.1p priority field.
CFI: Canonical Format Identifier is always set to 0 for Ethernet switches and to 1 for Token Ring-type networks.
VLAN ID: 12-bit VLAN field. Of the 4096 possible VLAN IDs, the maximum	number of possible VLAN configurations is 4094. A VLAN ID of 0 indicates priority frames, and value 4095 (FFF) is reserved. 
Understanding Native VLAN in 802.1Q Trunking
A frequent configuration error is to have different native VLANs. The native VLAN that is configured on each end of an 802.1Q trunk must be the same.
Cisco switches use Cisco Discovery Protocol (CDP) to warn of a native VLAN mismatch
By default, the native VLAN will be VLAN 1.
Switch(config-if)# switchport trunk native vlan vlan-id
Understanding DTP
DTP Modes Combination
VLAN Ranges and Mappings
ISL supports VLAN numbers in the range of 1 to 1005, whereas 802.1Q VLAN numbers are in the range of 1 to 4094. 
The default behavior of VLAN trunks is to permit all normal and extended-range VLANs across the link if it is an 802.1Q interface and to permit normal VLANs in the case of an ISL interface.
Supported VLAN on Catalyst Switchs	
VLAN Ranges
Configuring, Verifying, and Troubleshooting VLANs and Trunks
Step 1. Enter global configuration mode:
Switch# configure terminal
Step 2. Create a new VLAN with a particular ID number:
Switch(config)# vlan vlan-id
Step 3. (Optional.) Name the VLAN:
Switch(config-vlan)# name vlan-name
Assigning an Access Port to a VLAN
Step 1. From global configuration mode, enter the configuration mode for the particular port you want to add to the VLAN:
Switch(config)# interface interface-id
Step 2. Specify the port as an access port:
Switch(config-if)# switchport mode access
Switch(config-if)# switchport host
Step 3. Remove or place the port in a particular VLAN:
Switch(config-if)# [ no ] switchport access vlan vlan-id
Assigning an Access Port to a VLAN
Verifying the VLAN Configuration
Verifying the VLAN Configuration
Displaying Information About the Interface
Displaying Detailed Switch Port Information
Displaying MAC Address Table Information
Topology to Configure VLAN and Trunking
Configuring VLANs and Trunks
Step 1. Create VLAN 20 on both switches.
SW1(config)# vlan 20
SW1(config-vlan)# exit
% Applying VLAN changes may take few minutes. Please wait... 
Step 2. On SW1/2 configure port Ethernet 0/2 to be an access port and assign it to VLAN 20
SW1(config)# interface ethernet 0/2
SW1(config-if)# switchport mode access
SW1(config-if)# switchport access vlan 20
Step 3. Configure ports that connect SW1 and SW2 as trunks. Use the dot1Q encapsulation.
Trunk configuration on SW1:
SW1(config)# interface Ethernet 1/1
SW1(config-if)# switchport trunk encapsulation dot1q
SW1(config-if)# switchport trunk allowed vlan 1,20
SW1(config-if)# switchport mode trunk
Trunk configuration on SW2:
SW2(config)# interface Ethernet 1/2
SW2(config-if)# switchport trunk encapsulation dot1q
SW2(config-if)# switchport trunk allowed vlan 1,20
SW2(config-if)# switchport mode trunk
Verify Trunking
Best Practices for VLANs and Trunking
For the Local VLANs model, it is usually recommended to have only one to three VLANs per access module.
Avoid using VLAN 1 as the black hole for all unused ports. 
Try to always have separate voice VLANs, data VLANs, management VLANs, native VLANs, black hole VLANs, and default VLANs (VLAN 1).
In the local VLANs model, avoid VTP; it is feasible to use manually allowed VLANs in a network on trunks.
For trunk ports, turn off DTP and configure it manually. 
Use IEEE 802.1Q rather than ISL because it has better support for QoS and is a standard protocol.
Manually configure access ports that are not specifically intended for a trunk link.
Prevent all data traffic from VLAN 1; only permit control protocols to run on VLAN 1 (DTP, VTP, STP bridge protocol data units [BPDUs], Port Aggregation Protocol [PAgP], Link Aggregation Control Protocol [LACP], Cisco Discovery Protocol [CDP], and such.).
Avoid using Telnet because of security risks; enable Secure Shell (SSH) support on management VLANs.
Best Practices for VLANs and Trunking
DTP is useful when the status of the switch on the other end of the link is uncertain or might be changing over time. When the link is to be set to trunk in a stable manner, changing both ends to trunk nonegotiate accelerates the convergence time, saving up to 2 seconds upon boot time. We recommend this mode on stable links between switches that are part of the same core infrastructure.
On trunk links, it is recommended to manually prune the VLANs that are not used. 
It is also a good practice to have an unused VLAN as a native VLAN on the trunk links to prevent DTP spoofing.
If trunking is not used on a port, you can disable it with the interface level command switchport host . 
Voice VLAN Overview
Multiservice switches support a new parameter for IP telephony support that makes the access port a multi-VLAN access port. 
The new parameter is called a voice or auxiliary VLAN . Every Ethernet 10/100/1000 port in the switch is associated with two VLANs:
A native VLAN for data service that is identified by the PVID
A voice VLAN that is identified by the voice VLAN ID (VVID)
During the initial CDP exchange with the access switch, the IP phone is configured with a VVID.
The IP phone is also supplied with a QoS configuration using CDP.
Voice VLAN Overview
Switch Configuration for Wireless Network Support
Cisco offers the following two WLAN implementations:
The standalone WLAN solution is based on autonomous (standalone) access points (APs).
The controller-based WLAN solution is based on controller-based APs and WLCs (Wireless LAN Controllers).
Autonomous WLAN
In the autonomous (or standalone) solution, each AP operates independently and acts as a transition point between the wireless media and the 802.3 media. 
The data traffic between two clients flows via the Layer 2 switch when on the same subnet from a different AP infrastructure. As the AP converts the IEEE 802.11 frame into an 802.3 frame, the wireless client MAC address is transferred to the 802.3 headers and appears as the source for the switch. 
The destination, also a wireless client, appears as the destination MAC address. 

Controller-Based WLAN
In a controller-based solution, management, control, deployment, and security functions are moved to a central point: the wireless controller.
To implement a wireless network, APs and switches need to be configured. APs can be configured directly (autonomous APs) or through a controller (lightweight APs). 
Either way, configuring APs is a domain of the WLAN specialist. On the switch side, just configure VLANs and trunks on switches to support WLAN.

VLAN Trunking Protocol
VTP overview
VTP modes
VTP versions
VTP pruning
VTP authentication
VTP advertisements
VTP configuration and verifications
VTP configuration overwriting
VTP best practices
VTP Overview
VTP is a Layer 2 protocol that maintains VLAN configuration consistency by managing the additions, deletions, and name changes of VLANs across networks
Switches transmit VTP messages only on 802.1Q or ISL trunks. 
Cisco switches transmit VTP summary advertisements over the management VLAN (VLAN 1 by default) using a Layer 2 multicast frame every 5 minutes.
VTP domain is one switch or several interconnected switches sharing the same VTP environment but switch can be only in one VTP domain at any time. 
By default, a Cisco Catalyst switch is in the no-management-domain state or <null> until it receives an advertisement for a domain over a trunk link or until you configure a management domain.
Configurations that are made on a single VTP server are propagated across trunk links to all of the connected switches in the network. 
Configurations will be exchanged if VTP domain and VTP passwords match.
VTP is a Cisco proprietary protocol.
VTP Propagation
Step 1. An administrator adds a new VLAN definition.
Step 2. VTP propagates the VLAN information to all switches in the VTP domain.
Step 3. Each switch synchronizes its configuration to incorporate the new VLAN data.
VTP Modes
VTP Operation	
By default, Cisco IOS VTP servers and clients save VLANs to the vlan.dat file in flash memory, causing them to retain the VLAN table and revision number.
The erase startup-config command does not affect the vlan.dat file on switches in VTP client and server modes.
Switches that are in VTP transparent mode display the VLAN and VTP configurations in the show running-config command output because this information is stored in the configuration text file. 
If you perform erase startup-config on a VTP transparent switch you will delete its VLANs.
VTP Versions
Cisco Catalyst switches support three different versions of VTP: 1, 2, and 3.
It is importante to decide which version to use because they are not interoperable. 
Cisco recommends running only one VTP version for network stability.
The default VTP version that is enabled on a Cisco switch is Version 1. 
If you do need to change the version of VTP in the domain, the only thing that you need to do is to enable it on the VTP server; the change will propagate throughout the network.
VTP Version 1 and 2
Version-dependent transparent mode
VTP Version 1, a VTP transparent network device inspects VTP messages for the domain name and version 
VTP Version 2 forwards VTP messages in transparent mode, without checking the version.
Consistency check
In VTP Version 2, VLAN consistency checks, such as VLAN names and values, are performed. 
Token ring support
VTP Version 2 supports Token Ring LAN switching and VLANs.
Unrecognized type-length-value support
VTP Version 2 switches propagate received configuration change messages out other trunk links, even if they are not able to understand the message. 
VTP Version 3
Extended VLAN support
VTP also can be used to propagate extended VLANs
Domain name is not automatically learned
With VTPv2, a factory default switch that receives a VTP message will adapt the new VTP domain name. 
Better security
VTP domain password is secure during transmission and in the switch’s database.
Better database propagation. 
Only the primary server is allowed to update other devices and only one server per VTP domain is allowed to have this role.
Multiple Spanning Tree (MST) support
VTPv3 adds support for propagation of MST instances.
VTP Pruning
VTP Authentication
VTP domains can be secured by using the VTP password feature. 
It is important to make sure that all the switches in the VTP domain have the same password and domain name; otherwise, a switch will not become a member of the VTP domain. 
Cisco switches use the message digest 5 (MD5) algorithm to encode passwords in 16-byte words. 
These passwords propagate inside VTP summary advertisements. 
In VTP, passwords are case sensitive and can be 8 to 64 characters in length. 
The use of VTP authentication is a recommended practice.
VTP Advertisements
VTP Messages Types
Summary Advertisements
By default, Catalyst switches issue summary advertisements in 5-minute increments. Summary advertisements inform adjacent Catalysts of the current VTP domain name and the configuration revision number.
When the switch receives a summary advertisement packet, the switch compares the VTP domain name to its own VTP domain name. 
If the name differs, the switch simply ignores the packet. 
If the name is the same, the switch then compares the configuration revision to its own revision. 
If its own configuration revision is higher or equal, the packet is ignored. If it is lower, an advertisement request is sent.
VTP Messages Types
Subset Advertisements
When you add, delete, or change a VLAN in a Catalyst server, the Catalyst server where the changes are made increments the configuration revision and issues a summary advertisement. 
One or several subset advertisements follow the summary advertisement. 
A subset advertisement contains a list of VLAN information. 
Advertisement Requests are sent when:
The switch has been reset.
The VTP domain name has been changed.
The switch has received a VTP summary advertisement with a higher configuration revision than its own.
Upon receipt of an advertisement request, a VTP device sends a summary advertisement.	One or more subset advertisements follow the summary advertisement.
Configuring and Verifying VTP
Step 1. Configure VTP on all the switches, Switch 1 and Switch 3 as client mode where as Switch2 as server mode
Overwriting VTP Configuration (Very Common Issue with VTP)
Overwriting VTP Configuration (Very Common Issue with VTP)
Overwriting VTP Configuration (Very Common Issue with VTP)
VTP Key Points
Avoid, as much as possible, VLANs that span the entire network.
The VTP revision number is stored in NVRAM and is not reset if you erase the switch configuration and reload it. To reset the VTP revision number to zero, use the following two options:
Change the switch’s VTP domain to a nonexistent VTP domain, and then change the domain back to the original name.
Change the switch’s VTP mode to transparent and then back to the previous VTP mode.
Best Practices for VTP Implementation
VTP is often used in a new network to facilitate the implementation of VLANs.
However, as the network grows larger, this benefit can turn into a liability. 
If a VLAN is deleted by accident on one server, it is deleted throughout the network. 
If a switch that already has a VLAN database defined is inserted into the network, it can hijack the VLAN database by deleting added VLANs. 
Because of this, it is the recommended practice to configure all switches to transparent VTP mode and manually add VLANs as needed, especially in a larger campus network. 
VTP configuration is usually good for small environments.

Implementing EtherChannel in a Switched Network
The need for EtherChannel technology
Port aggregation negotiation protocols
Configuration steps for bundling interfaces into a Layer 2 EtherChannel
Configuring EtherChannel
Changing EtherChannel load-balancing behavior
How EtherChannel load-balancing works
The role of EtherChannel Guard
The Need for EtherChannel
EtherChannel Overview
EtherChannel is a technology that was originally developed by Cisco as a LAN switchto- switch technique of grouping several Fast or Gigabit Ethernet ports into one logical channel. 
This technology has many benefits:
It relies on the existing switch ports. There is no need to upgrade the switch-to-switch link to a faster and more expensive connection.
Most of the configuration tasks can be done on the EtherChannel interface instead of on each individual port, thus ensuring configuration consistency throughout the switch-to-switch links.
Load balancing is possible between the links that are part of the same EtherChannel. Depending on the hardware platform, you can implement one or several methods, such as source-MAC to destination-MAC or source-IP to destination-IP load balancing across the physical links.
EtherChannel Mode Interactions
EtherChannel can be established using one of the following three mechanisms:
LACP: IEEE’s negotiation protocol
PAgP: Cisco’s negotiation protocol
Static persistence: No negotiation protocol
LACP
Link Aggregation Control Protocol (LACP) is part of an IEEE specification (802.3ad) that allows several physical ports to be bundled together to form a single logical channel. LACP allows a switch to negotiate an automatic bundle by sending LACP packets to the peer.
It ensures that when EtherChannel is created, all ports have the same type of configuration speed, duplex setting, and VLAN information. Any port modification after the creation of the channel will also change all the other channel ports.
The switch with the lowest system priority is allowed to make decisions about what ports actively participate in EtherChannel. 
LACP
Ports become active according to their port priority.
A lower number means higher priority. 
Commonly up to 16 links can be assigned to an EtherChannel, but only 8 can be active at a time.
Nonactive links are placed into a standby state and are enabled if one of the active links goes down.
The maximum number of active links in an EtherChannel varies between switches.

LACP Modes of Operation
These are the LACP modes of operation:
Active: Enable LACP
Passive: Enable LACP only if an LACP device is detected
The following are some additional parameters that you can use when configuring LACP:
System priority
Each switch running LACP must have a system priority. The system priority can be specified automatically or through the CLI. The switch uses the MAC address and the system priority to form the system ID.
Port priority
Each port in the switch must have a port priority. The port priority can be specified automatically or through the CLI. 
Administrative key
Each port in the switch must have an administrative key value, which can be specified automatically or through the CLI. The administrative key defines the capability of a port to aggregate with other ports, determined by these factors: the port’s physical characteristics, such as data rate, duplex capability, and point-to-point or shared medium.
PAgP
Port Aggregation Protocol (PAgP) provides the same negotiation benefits as LACP.
PAgP is a Cisco proprietary protocol, and it will work only on Cisco devices. 
PAgP packets are exchanged between switches over EtherChannel-capable ports. 
Neighbors are identified and capabilities are learned and compared with local switch capabilities. 
Ports that have the same capabilities are bundled together into an EtherChannel. 
PAgP forms an EtherChannel only on ports that are configured for identical VLANs or trunking.
PAgP will automatically modify parameters of the EtherChannel if one of the ports in the bundle is modified. 
PAgP and LACP are not compatible.
PAgP Modes of Operation
These are the following two PAgP modes of operation:
■ Desirable: Enable PAgP
■ Auto: Enable PAgP only if a PAgP device is detecte
Statically Bundle Links
Negotiation with either LACP or PAgP introduces overhead and delay in initialization. 
As an alternative, you can statically bundle links into an EtherChannel.
This method introduces no delays but can cause problems if not properly configured on both ends.
Layer 2 EtherChannel Configuration Guidelines
Before implementing EtherChannel in a network, plan the following steps necessary to make it successful:
The first step is to identify the ports that you will use for the EtherChannel on both switches. 
Each interface should have the appropriate protocol identified (PAgP or LACP), have a channel group number to associate all the given interfaces with a port group, and be configured whether negotiation should occur.
After the connections are established, make sure that both sides of the EtherChannel have formed and are providing aggregated bandwidth.
Layer 2 EtherChannel Configuration Guidelines
Follow these guidelines and restrictions when configuring EtherChannel interfaces:
EtherChannel support
All Ethernet interfaces on all modules support EtherChannel, with no requirement that interfaces be physically contiguous or on the same module.
Speed and duplex
Configure all interfaces in an EtherChannel to operate at the same speed and in the same duplex mode.
VLAN match
All interfaces in the EtherChannel bundle must be assigned to the same VLAN or be configured as a trunk.
Range of VLANs
An EtherChannel supports the same allowed range of VLANs on all the interfaces in a trunking Layer 2 EtherChannel.
Layer 2 EtherChannel Configuration Guidelines
STP path cost
Interfaces with different STP port path costs can form an EtherChannel as long as they are compatibly configured. 
Setting different STP port path costs does not, by itself, make interfaces incompatible for the formation of an EtherChannel.
Port channel versus interface configuration
After you configure an EtherChannel, any configuration that you apply to the port channel interface affects the EtherChannel. 
Any configuration that you apply to the physical interfaces affects only the specific interface that you configured.
EtherChannel Load-Balancing Options
Configuring EtherChannel in a Switched Network
Configuring EtherChannel in a Switched Network
Step 1. 
Configure the two ports that connect each switch to use channel group 1 and LACP active mode:
Switch1# configure terminal
Switch1(config)# interface range Ethernet 1/1-2
Switch1(config-if-range)# channel-group 1 mode active
Creating a port-channel interface Port-channel 1
Step 2. 
Enter interface configuration mode for the newly created port channel interface and configure it for trunk mode using dot1Q:
Switch1(config)# interface port-channel 1
Switch1(config-if)# switchport trunk encapsulation dot1q
Switch1(config-if)# switchport mode trunk
Configuring EtherChannel in a Switched Network
Step 3. 
On Switch 1, enter the show etherchannel summary command:
Configuring EtherChannel in a Switched Network
Step 4. 
Enter the show etherchannel load-balance command to verify which information EtherChannel uses to load balance traffic:
Chapter 3 Summary
Implementing VLANs and trunks in campus switched architecture
Understanding the concept of VTP and its limitation and configurations
Implementing and configuring EtherChannel


Chapter 3 Labs
CCNPv7.1 SWITCH Lab3.1 VLAN TRUNK VTP
CCNPv7.1 SWITCH Lab3.2 ETHERCHANNEL

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva2

Chapter 4: Spanning Tree in Depth
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 4 Objectives
Spanning Tree Protocol (STP) overview, its operations, and history
Implement Rapid Spanning Tree Protocol (RSTP)
Describe how and where to configure the following features: PortFast, UplinkFast, BackboneFast, BPDU Guard, BPDU Filter, Root Guard, Loop Guard, Unidirectional Link Detection, and FlexLinks
Configure Multiple Spanning Tree (MST)
Troubleshooting STP
Spanning Tree Protocol Overview
Spanning Tree Protocol Overview
Upon completing this section, you will be able to meet these objectives:
Explain the need for STP
List different standards of STP
Describe basic STP operation
Describe bridge protocol data units
Explain the root bridge election
Explain the root port election
Explain designated port election
Explain STP port states
Explain PVST+
Explain STP topology changes
STP Need
Redundant topology can eliminate single points of failure in the network , however, STP blocks certain ports, so there is only one active path to each segment .

Redundant Topology Problems
Broadcast storms
Each switch on a redundant network floods broadcast frames endlessly. These frames then travel around the loop in all directions.
Multiple frame transmission
Multiple copies of the same unicast frames may be delivered to destination station, which can cause problems with the receiving protocol. Multiple copies of the same frame can cause unrecoverable errors.
MAC database instability
If a loop occurs, the same source MAC address could be seen on multiple interfaces causing instability. Data forwarding can be impaired when the switch consumes the resources that are coping with instability in the MAC address table.
Solution	
STP allows physical path redundancy while preventing the undesirable effects of active loops in the network. 
STP forces certain ports into a standby state so that they do not listen, forward, or flood data frames. 
There is only one active path to each network segment.
If there is a problem with connectivity to any of the segments, STP reestablishes connectivity by automatically activating a previously inactive path. 
STP uses bridge protocol data units (BPDUs) for its operations. 
STP Standards
STP Operations
STP provides loop resolution by managing the physical path to the given network segment, by performing the following three steps:
1. Elects one root bridge
Only one bridge can act as the root bridge. The root bridge is the reference point; all data flows in the network are from the perspective of this switch. All ports on a root bridge are forwarding traffic.
2. Selects the root port on the nonroot bridge
One port on each nonroot bridge I the root port. It is the port with the lowest-cost path from the nonroot bridge to the root bridge. By default, STP path cost is calculated from the bandwidth of the link. You can also set STP path cost manually.
3. Selects the designated port on each segment
There is one designated port on each segment. It is selected on the bridge with the lowest-cost path to the root bridge.
STP Operations
STP Port Roles
Bridge Protocol Data Units
STP uses BPDUs to exchange STP information, specifically for root bridge election and for loop identification. 
By default, BPDUs are sent out every 2 seconds. 
BPDUs are generally categorized into two types:
Configuration BDPUs
Used for calculating the STP
TCN (topology change notification) BPDUs
Used to inform changes in the network topology
The BPDU Frame
Protocol ID: Identifies the STP
Version: Identifies the current version of the protocol
Message Type: Identifies the type of BPDU (configuration or TCN BPDU)
Flags: Used in response to a TCN BPDU
Root Bridge ID: Identifies the bridge ID (BID) of the root bridge
Root Path Cost: Identifies the cost from the transmitting switch to the root
Sender Bridge ID: Identifies the BID of the transmitting switch
Port ID: Identifies the transmitting port
Message Age: Indicates the age of the current BPDU
Max Age: Indicates the timeout value
Hello Time: Identifies the time interval between generations of configuration BPDUs by the root
Forward Delay: Defines the time a switch port must wait in the listening and learning state
Root Bridge Election
The root bridge is chosen with an election. 
In STP, each switch has a unique BID that consists of the following:
Bridge priority (a value between 0 and 65,535, with the default being 32,768)
MAC address




The root bridge is selected based on the lowest BID.
 If all switches in the network have the same priority, the switch with the lowest MAC address becomes the root bridge
Root Port Election
After the root bridge is elected, each nonroot bridge must figure out where it is in relation to the root bridge. 
Root port is the port with the best path to the root bridge.
To determine root ports on nonroot bridges, cost value is used. 
The path cost is the cumulative cost of all links to the root bridge. 
Root port indicates the lowest cost to the root bridge.
Designated Port Election
After the root bridge and root ports on nonroot bridges have been elected, to prevent the loops STP has to identify which port on the segment will forward the traffic.
Only one of the links on a segment should forward traffic to and from that segment. 
The designated port, the one forwarding the traffic, is also chosen based on the lowest cost to the root bridge.
On the root bridge, all ports are designated.
If there are two paths with equal cost to the root bridge, STP uses the following criteria for best path determination and consequently for determination of designated and nondesignated ports on the segment:
Lowest root BID
Lowest root path cost to root bridge
Lowest sender BID
Lowest sender port ID
STP Process
STP Port States
Per-VLAN STP Plus (PVST+)
Per-VLAN STP Plus (PVST+) is a Cisco implementation of STP that provides a separate spanning-tree instance for each configured VLAN in the network.
Per-VLAN STP Plus (PVST+)
Spanning-tree operation requires that each switch has a unique BID. 
To carry BID information, the extended system ID is accommodated. 
The original 16-bit bridge priority field is split into two fields, resulting in the following components in the BID:
Bridge priority
A 4-bit field used to carry bridge priority. The default priority is 32,768, which is the midrange value. The priority is conveyed in discrete values in increments of 4096.
Extended system ID
A 12-bit field carrying the VLAN ID.
MAC address
A 6-byte field with the MAC address of the switch. 
STP Topology Changes

Rapid Spanning Tree Protocol
Upon completing this section, you will be able to meet these objectives:
List and explain RSTP port roles
Compare RSTP and STP port states
Explain how STP handles topology changes
Describe RSTP link types
Configure and modify STP behavior
Explain how RSTP handles topology changes
RSTP Port Roles
RSTP defines the following port roles :
Root
The root port is the switch port on every nonroot bridge that is the chosen path to the root bridge. 
There can be only one root port on every switch. 
The root port is considered as part of active topology. 
It forwards, sends, and receives BPDUs (data messages).
Designated
Each switch has at least one switch port as the designated port for the segment. 
In active topology, the switch with the designated port receives frames on the segment that are destined for the root bridge. 
There can be only one designated port per segment.
RSTP Port Roles
RSTP defines the following port roles :
Alternate
The alternate port is a switch port that offers an alternate path toward the root bridge. 
It assumes a discarding state in an active topology. 
The alternate port makes a transition to a designated port if the current designated path fails.
Disabled
A disabled port has no role within the operation of spanning tree.
Backup
The backup port is an additional switch port on the designated switch with a redundant link to the shared segment for which the switch is designated. 
The backup port has the discarding state in active topology.
RSTP Port Roles
Comparison of RSTP and STP Port States
RSTP Ports States
RSTP Topology Changes
With RSTP, the TC propagation is now a one-step process. In fact, the initiator of the topology change floods this information throughout the network, as opposed to 802.1D, where only the root did. 
This mechanism is much faster than the 802.1D equivalent.
In just a few seconds, or a small multiple of hello times, most of the entries in the CAM tables of the entire network (VLAN) flush.
Why does RSTP not consider link failure a topology change? 
Loss of connectivity does not provide new paths in topology. If a switch loses the link to a downstream switch, the downstream switch either has an alternate path to the root bridge or it does not. 
If the downstream switch has no alternate path, no action will be taken to improve convergence.
If the downstream switch has an alternate path, the downstream switch will unblock it and consequently generate its own BPDUs with the TC bit set.
Like with STP, PortFast-enabled ports do not create topology changes. 
Configuring and Modifying STP Behavior
Changing STP Priority
It is not advised for the network to choose the root bridge by itself. If all switches have default STP priorities, the switch with the lowest MAC address will become the root bridge. 
The oldest switch will have the lowest MAC address because the lower MAC addresses were factory-assigned first. 
To manually set the root bridge, you can change a switch’s priority
Note 
It is highly recommended to configure the distribution or core switches to become the root bridge.
Changing STP Priority
The priority can be a value between 0 and 65,535, in increments of 4096. The default value is 32,768.
The better solution is to use spanning-tree vlan vlan-id root { primary | secondary } command.
This command is actually a macro that lowers the switch’s priority number for it to become the root bridge.
To configure the switch to become the root bridge for a specified VLAN, use the primary keyword. 
Use the secondary keyword to configure a secondary root bridge. 
The spanning-tree root command calculates the priority by learning the current root priority and lowering the 4096 value to it. 
STP Path Manipulation
STP Path Manipulation
You can modify port cost by using the spanning-tree vlan vlan-list cost cost-value command.
The cost value can be between 1 and 65,535.
You can modify the port priority by using the spanning-tree vlan vlan-list port-priority port-priority command. The value of port priority can be between 0 and 255; the default is 128. 
A lower port priority means a more preferred path to the root bridge.
STP Timers
STP uses three different timers to ensure proper loop-free convergence. The three key STP timers and their default values are as follows:
Hello time
The time between each BPDU that is sent on a port. Equals 2 seconds, by default.
Forward delay
The time that is spent in the listening and learning state. Equals 15 seconds, by default.
Max (maximum) age
Controls the maximum length of time that passes before a bridge port saves its configuration BPDU information. Equals 20 seconds, by default.
STP Timers
The transition between port states takes from 30 to 50 seconds, depending on the topology change. 
This can be adjusted with STP timers. STP hello time can be tuned between 1 and 10 seconds, forward delay between 4 and 30 seconds, and maximum age between 6 and 40 seconds.
To manually configure timers, use the spanning-tree [ vlan vlan-id ] { hello-time | forward-time | max-age } seconds command. 
Changing the STP Mode to RSTP






The convergence time for RSTP is much shorter than for STP. The entire convergence happens at the speed of BPDU transmission. 
That can be less than 1 second.

Cisco Spanning Tree Protocol Toolkit
Provides tools to better manage STP. 
The key features of are as follows:
UplinkFast: Enables fast uplink failover on access switch
BackboneFast: Enables fast convergence in distribution or core layer when STP change occurs
PortFast: Configures access port to transition directly to forwarding state
Cisco Spanning Tree Protocol Toolkit
The key features of the Cisco STP Toolkit that ensure STP stability are as follows:
BPDU Guard
Disables the PortFast-enabled port if a BPDU is received
BPDU Filter
Suppresses BPDUs on ports
Root Guard
Prevents external switches from becoming roots
Loop Guard
Prevents an alternate port from becoming the designated port if no BPDUs are received
Use UplinkFast
If forwarding uplink fails, it will take 30 to 50 seconds for the other uplink to take over.
UplinkFast is a Cisco proprietary solution that greatly reduces convergence time.
The UplinkFast feature is based on the definition of an uplink group. On a given switch, the uplink group consists of the root port and all the ports that provide an alternate connection to the root bridge. If the root port fails, which means if the primary uplink fails, a port with the next lowest cost from the uplink group is selected to immediately replace it.
The total time to recover the primary link failure will normally be less than 1 second.
Use UplinkFast
UplinkFast is a Cisco proprietary feature
By default, UplinkFast is disabled.
To enable UplinkFast, use the following command:
ASW(config)# spanning-tree uplinkfast
With RSTP, the UplinkFast mechanism is already integrated into the protocol in a standards-based way.
Use BackboneFast
When an indirect link failure occurs, BackboneFast checks whether an alternative path exists to the root bridge. 
Indirect failure is when a link that is not directly connected to a switch fails.
Use BackboneFast
Normally a switch must wait for the maximum age timer to expire before responding to the inferior BPDUs. 
However BackboneFast searches for an alternative path:
If the inferior BPDU arrives on a port that is blocked, the switch assumes that the root port and all other blocked ports are an alternative path.
If the inferior BPDU arrives on a port that is root, the switch assumes all blocked are an alternate path. 
If no ports are blocked, the switch assumes that it lost connectivity with the root bridge and considers itself as the root bridge.
After the switch identifies potential alternative ports, it starts sending RLQs (request link queries). By sending these queries, it finds out whether upstream switches have a path to the root bridge.

Use BackboneFast
To configure BackboneFast, use the following command:
DSW1(config)# spanning-tree backbonefast
By default, BackboneFast is disabled.
To verify the current BackboneFast state, issue the following command:
DSW1# show spanning-tree backbonefast
BackboneFast is enabled
BackboneFast was implemented into RSTP. RSTP implementation differs a bit from BackboneFast. Whereas BackboneFast relies on RLQ messages to validate the current root bridge, RSTP relies on cached information.
Use PortFast
When PortFast is enabled, the port transitions immediately from blocking to forwarding.
PortFast should be enabled on access layer switches where the hosts are connected.
An additional benefit of using PortFast is that TCN BPDUs are not sent when a switch port in PortFast mode goes up or down.
By default, PortFast is disabled on all switch ports. 
You can configure PortFast in two ways: per port and globally. 
If you configure PortFast globally, all ports that are configured as access ports automatically become PortFast enabled, and the port will immediately transition to forwarding.
If a port does receive a BPDU, that port will go into blocking mode. 
If you configure PortFast per port
The port will be PortFast enabled even if it receives BPDUs
Use PortFast
PortFast Configuration for a Trunk
Never use the PortFast feature on switch ports that connect to other switches, hubs, or routers. 
You can also enable PortFast on trunk ports. 
This is useful if you have a trunk enabled for a host such as a server that needs multiple VLANs. 
To enable a port for PortFast on an interface that connects to such a server, use the following interface configuration commands:
Securing PortFast Interface with BPDU Guard
BPDU Guard protects the integrity of ports that are PortFast enabled. 
If any BPDU is received on a PortFast-enabled port, that port is put into err-disabled state. 
That means the port is shut down and must be manually reenabled or automatically recovered through the error-disabled timeout function.



It is highly recommended to always enable BPDU Guard on all PortFast-enabled ports. 
Securing PortFast Interface with BPDU Guard
By default, BPDU Guard is disabled on all switch ports. 
BPDU Guard can be configured in two ways, globally and per port.






Global configuration is conditional: If the port is not PortFast enabled, BPDU Guard will not be activated.
Disabling STP with BPDU Filter
BPDUs are sent on all ports, even if they are PortFast enabled. 
You should always run STP to prevent loops. 
However, in special cases, you need to prevent BPDUs from being sent out. 
You can achieve that by using BPDU Filter.
Disabling STP with BPDU Filter
BPDU Filter behaves differently if applied globally or on a per-port basis.
When enabled globally, BPDU Filter has these attributes:
It affects all operational PortFast ports on switches that do not have BPDU Filter configured on the individual ports.
If BPDUs are detected, the port loses its PortFast status, BPDU Filter is disabled, and the STP sends and receives BPDUs on the port as it would with any other STP port on the switch.
Upon startup, the port transmits ten BPDUs. If this port receives any BPDUs during that time, PortFast and PortFast BPDU Filter are disabled.
When enabled on an individual port, BPDU Filter has these attributes:
It ignores all BPDUs received.
It sends no BPDUs.
Use Root Guard
The Root Guard feature forces an interface to become a designated port to prevent surrounding switches from becoming a root switch. 
In other words, Root Guard provides a way to enforce the root bridge placement in the network. 
If the bridge receives superior STP BPDUs on a Root Guard-enabled port, the port moves to a root-inconsistent STP state and the switch does not forward traffic out of that port.
Use Root Guard
The current design recommendation is to enable Root Guard on all access ports so that  a root bridge is not established through these ports. 

Configuring and Verifying Root Guard
Loop Guard Overview
STP relies on continuous reception or transmission of BPDUs based on the port role. 
The designated port transmits BPDUs, and the nondesignated port receives BPDUs.
When one of the ports in a physically redundant topology no longer receives BPDUs, the STP conceives that the topology is loop free. 
Eventually, the blocking port from the alternate or backup port becomes designated and moves to a forwarding state. 
This situation creates a loop.
The Loop Guard feature makes additional checks. If BPDUs are not received on a nondesignated port, and Loop Guard is enabled, that port is moved into the STP loopinconsistent blocking state, instead of the listening/learning/forwarding state. 

Loop Guard Overview
Loop Guard Overview
When the Loop Guard blocks an inconsistent port, this message is logged:


Once the BPDU is received on a port in a loop-inconsistent STP state, the port transitions into another STP state. After recovery, this message is logged:
Loop Guard Placement
The Loop Guard feature is enabled on a per-port basis. 
However, as long as it blocks the port on the STP level, Loop Guard blocks inconsistent ports on a per-VLAN basis
By default, Loop Guard is disabled. You can configure Loop Guard globally or on a port-per-port basis.
If you enable Loop Guard globally, then effectively, it is enabled on all point-to-point links.
Loop Guard vs Root Guard
The Root Guard is mutually exclusive with the Loop Guard. 
The Root Guard is used on designated ports, and it does not allow the port to become nondesignated. 
The Loop Guard works on nondesignated ports and does not allow the port to become designated through the expiration of maximum age. 
The Root Guard cannot be enabled on the same port as the Loop Guard.
When the Loop Guard is configured on the port, it disables the Root Guard configured on the same port.
Use UDLD
Unidirectional links can cause spanning-tree topology loops. 
Unidirectional Link Detection (UDLD) enables devices to detect when a unidirectional link exists and also to shut down the affected interface.
UDLD is useful on a fiber port to prevent network issues resulting in miswiring at the patch panel causing the link to be in up/up status but the BPDUs are lost.
UDLD Overview
UDLD Overview
UDLD Overview
UDLD is a Layer 2 protocol that works with the Layer 1 mechanisms to determine the physical status of a link.
Both UDLD peers discover each other by exchanging special frames that are sent to well-known MAC address 01:00:0C:CC:CC:CC
In an EtherChannel bundle, UDLD will error-disable only the physical link that has failed.
UDLD messages are sent at regular intervals. This timer can be modified. The default setting varies between platforms. The typical value is 15 seconds.
UDLD is a Cisco proprietary protocol that is also defined in RFC 5171.

UDLD Operation
After UDLD detects a unidirectional link, it can take two courses of action, depending on configured mode. UDLD has two modes:
Normal mode
When a unidirectional link is detected, the port is allowed to continue its operation. UDLD just marks the port as having an undetermined state. A syslog message is generated.
Aggressive mode
When a unidirectional link is detected, the switch tries to reestablish the link. It sends one message a second, for 8 seconds. If none of these messages is sent back, the port is placed in error-disabled state.
UDLD Configuration
As with other commands, like PortFast, you can enable UDLD on a per-port basis or globally. 
It is supported only at the fiber ports.






Use the udld reset command to reset all the interfaces that were shut down by UDLD.
Comparing Loop Guard with UDLD
UDLD Recommended Practices
Typically, it is deployed on any fiber-optic interconnection.
Use UDLD aggressive mode for best protection.
Turn on in global configuration to avoid operational errors and misses.
Use FlexLinks
FlexLinks are a pair of a Layer 2 interfaces, where one interface is configured to act as a backup to the other.
FlexLinks provide link-level redundancy that is an alternative to STP. 
STP is automatically disabled on FlexLinks interfaces.
FlexLinks Configuration and Verification	
FlexLinks Guidelines
You can configure only one FlexLinks backup link for any active link
An interface can belong to only one FlexLinks pair.
Neither of the links can be a port that belongs to an EtherChannel. However, you can configure two port channels as FlexLinks.
A backup link does not have to be the same type (Fast Ethernet, Gigabit Ethernet, or port channel) as the active link. 
STP is disabled on FlexLinks ports
STP Stability Mechanisms Recommendations
STP Stability Mechanisms Recommendations
PortFast: Apply to all end-user ports. To secure PortFast-enabled ports, always combine PortFast with BPDU Guard.
Root Guard: Apply to all ports where root is never expected.
Loop Guard: Apply to all ports that are or can become nondesignated.
UDLD: The UDLD protocol enables devices to monitor the physical configuration of the cables and detect when a unidirectional link exists..
Depending on the security requirements of an organization, the port security feature can be used to restrict the ingress traffic of a port by limiting the MAC addresses that are allowed to send traffic into the port.
Configuring Multiple Spanning Tree Protocol
Multiple Spanning Tree Protocol 802.1s
The main purpose of MST is to reduce the total number of spanning-tree instances to match the physical topology of the network and thus reduce the CPU cycles of a switch
MST is a concept of mapping one or more VLANs to a single STP instance.
The number of instances of spanning tree is reduced to the number of links that are available.
VLAN Load Balancing
Two links and 1000 VLANs
The 1000 VLANs map to two MST instances. Rather than maintaining 1000 spanning trees, each switch needs to maintain only two spanning trees, reducing the need for switch resources.
Introducing MST
MST allows for the building of multiple spanning trees over trunks by grouping and associating VLANs to spanning-tree instances. 
Each instance may have a topology that is independent of other spanning-tree instances. 
This architecture provides multiple forwarding paths for data traffic and enables load balancing. 
A failure in one forwarding path does not affect other instances with different forwarding paths; hence, this architecture improves network fault tolerance.
MST converges faster than PVRST+ and is backward compatible with 802.1D STP, 802.1w (RSTP), and the Cisco PVST+ architecture.
MST 
Benefits
Load-balancing scheme is still possible because half the VLANs follow one separate instance.
The switch utilization is low because it has to handle only two instances.

Drawbacks
The protocol is more complex than the usual spanning tree and therefore requires additional training of the operation staff.
Interaction with legacy bridges is sometimes challenging.
MST Regions
MST differs from the other spanning-tree implementations in combining some but not necessarily all VLANs into logical spanning-tree instances. 
This difference raises the problem of determining which VLAN is supposed to be associated with which instance.
VLAN-to-instance association is communicated by tagging the BPDUs so that the receiving device can identify the instances and the VLANs to which they apply.
To provide this logical assignment of VLANs to spanning trees, each switch that is running MST in the network has a single MST configuration consisting of following three
An alphanumeric configuration name (32 bytes)
A configuration revision number (2 bytes)
A 4096-element table that associates each of the potential 4096 VLANs supported on the chassis with a given instance
MST Regions
To be part of a common MST region, a group of switches must share the same configuration attributes. 
It is the responsibility of the network administrator to propagate the configuration properly throughout the region.
MST Regions
The exact VLAN-to-instance mapping is not propagated in the BPDU because the switches need to know only whether they are in the same region as a neighbor.
Therefore, only a digest of the VLAN-to-instance mapping table is sent, along with the revision number and the name. 
After a switch receives a BPDU, it extracts the digest and compares it with its own computed digest. 
If the digests differ, the mapping must be different, so the port on which the BPDU was received is at the boundary of a region.
MST Configuration Revision
The configuration revision number gives you a method of tracking changes that are made to the MST region. 
It does not automatically increase each time that you make changes to the MST configuration. 
Each time that you make a change, you should increase the revision number by one.
STP Instances with MST
MST supports a number of instances. 
Instance 0 is the internal spanning tree (IST).
STP Instances with MST
All six VLAN instances initially belong to MSTI0. This is the default behavior. 
Then make the half of VLAN instances (11, 22, and 33) mapped to MSTI1, and the other half (44, 55, and 66) mapped to MSTI2. 
If different root bridges are configured for MSTI1 and MSTI2, their topologies will converge differently. 
By having different Layer 2 topologies between MST instances, links are more evenly utilized.
STP Instances with MST
Within a topology where multiple variations of STP are used, Common Spanning Tree (CST) topology considers an MST region as a single black box. 
CST maintains a loopfree topology with the links that connect the regions to each other and to switches that are not running MST
Extended System ID for MST
As with PVST, the 12-bit Extended System ID field is used in MST. 
In MST, this field carries the MST instance number.
Configuring and Verifying MST
Configuring MST with the CCNP Region
MST Instance 1 and 2 Configuration
MST is configured with three instances. 
VLANs 2 and 3 belong to instance 1. 
VLANs 4 and 5 belong to instance 2. 
All other VLANs between 1 and 4094, that are not in instances 1 or 2, belong to instance 0.
SPT Root Bridge Configuration
Verifying MST
Verifying MST Digest
Verifying MST Instances Mappings
Configuring MST Path Cost
Path cost functions the same as with other STPs, except with MST port costs are configured per instance.
Configuring MST Port Priority
Port priority functions the same as with other STPs, except with MST port priorities are configured per instance.
MST Protocol Migration
Ensure that all switch-to-switch links on which a rapid transition is desired are full duplex. 
Edge ports are defined through the PortFast feature.
Carefully decide how many instances are needed in the switched network, and keep in mind that an instance translates to a logical topology.
Decide what VLANs to map onto those instances, and carefully select a root and a backup root for each instance.
Choose a configuration name and a revision number that will be common to all switches in the network. 
Cisco recommends that you place as many switches as possible into a single region; it is not advantageous to segment a network into separate regions.
MST Protocol Migration
Avoid mapping any VLANs onto instance 0.
Migrate the core first. Change the STP type to MST, and work your way down to the access switches.
The configuration of the features such as the PortFast, BPDU Guard, BPDUF Filter, Root Guard, and Loop Guard are also applicable in MST mode. 
If you have already enabled these features in the PVST+ mode, it remains active after the migration to MST mode.
Chapter 4 Summary
Spanning Tree Protocol (STP) overview, its operations, and history
Implement Rapid Spanning Tree Protocol (RSTP)
Describe how and where to configure the following features: PortFast, UplinkFast, BackboneFast, BPDU Guard, BPDU Filter, Root Guard, Loop Guard, Unidirectional Link Detection, and FlexLinks
Configure Multiple Spanning Tree (MST)
Troubleshooting STP
Chapter 4 Labs
CCNPv7.1 SWITCH Lab4.1 STP
CCNPv7.1 SWITCH Lab4.2 MST

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva3
Chapter 5: Inter-VLAN Routing
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 5 Objectives
Given an enterprise network, design, implement, and verify inter-VLAN routing using an external router or a multilayer switch, using either switch virtual interfaces or routed interfaces
Understand Layer 3 EtherChannel and its configuration
Understand DHCP operation and its implementation and verification in a given enterprise network
Describing Inter-VLAN Routing
Describing Inter-VLAN Routing
Introduction to inter-VLAN routing
Inter-VLAN routing using an external router
Inter-VLAN routing with switch virtual interfaces
Routing with routed ports
Configuring inter-VLAN routing using SVI and routed ports
Troubleshooting inter-VLAN routing
Introduction to Inter-VLAN Routing
Because VLANs isolate traffic to a defined broadcast domain and subnet, network devices in different VLANs cannot communicate with each other natively.
The devices in each VLAN can communicate to the network devices in another VLAN only through a Layer 3 routing device
The following devices can provide inter-VLAN routing:
Any Layer 3 multilayer Catalyst switch
Any external router with an interface that supports trunking (router-on-a-stick)
Any external router or group of routers with a separate interface in each VLAN
Introduction to Inter-VLAN Routing
Router vs MLS for IVR
Router-on-a-stick is simple to implement because routers are usually available in every network, but most enterprise networks use multilayer switches to achieve high packet processing rates using hardware switching. 
Layer 3 switches usually have packet-switching throughputs in the millions of packets per second (pps), whereas traditional general-purpose routers provide packet switching in the range of 100,000 pps to more than 1 million pps.
All the Catalyst multilayer switches support three different types of Layer 3 interfaces:
Routed port: A pure Layer 3 interface similar to a routed port on a Cisco IOS router.
Switch virtual interface (SVI): A virtual VLAN interface for inter-VLAN routing. In other words, switch virtual interfaces (SVIs) are the virtual routed VLAN interfaces.
Bridge virtual interface (BVI): A Layer 3 virtual bridging interface.
Inter-VLAN Routing Using an External Router
Configure subinterfaces so that R1 that will route between PC1 (VLAN10) and PC2 (VLAN20).
Configure a trunk so that R1 will receive the traffic that needs to be routed.
Routing with an External Router Configuration
Configure router subinterface for routing of VLAN 10  / VLAN 20 traffic.
R1(config)# interface ethernet 0/0.10
R1(config-subif)# encapsulation dot1q 10
R1(config-subif)# ip address 10.0.10.1 255.255.255.0
R1(config)# interface ethernet 0/0.20
R1(config-subif)# encapsulation dot1q 20
R1(config-subif)# ip address 10.0.20.1 255.255.255.0
Configure a subinterface for native VLAN traffic.
R1(config)# interface ethernet 0/0.1
R1(config-subif)# encapsulation dot1q 1 native
R1(config-subif)# ip address 10.0.1.1 255.255.255.0
Verify configuration
Routing with an External Router Configuration
Configure switch trunk port. Allow only VLAN 1, 10, and 20 traffic.
SW1(config)# interface ethernet 0/0
SW1(config-if)# switchport trunk encapsulation dot1q
SW1(config-if)# switchport mode trunk
SW1(config-if)# switchport trunk allowed vlan 1,10,20
External Routers: Advantages Disadvantages
The following are advantages of external router usage:
An external router works with any switch because Layer 3 services are not required on the switch. Many switches do not contain Layer 3 forwarding capability, especially switches that are used at the access layer of a hierarchical network. 
The implementation is simple. Only one switch port and one router interface require configuration. 
If the network design includes only Layer 2 switches, the design and also the process for troubleshooting traffic flow become very simple because there is only one place in the network where VLANs interconnect.
External Routers: Advantages Disadvantages
The following are disadvantages of external router usage:
The router is a single point of failure.
A single traffic path may become congested. With a router-on-a-stick model, the trunk link is limited by the speed of the router interface being shared across all trunked VLANs
Latency may be introduced as frames leave and reenter the switch chassis multiple times and as the router makes software-based routing decisions. 
Inter-VLAN Routing Using Switch Virtual Interfaces
An SVI is a virtual interface configured within a multilayer switch, as compared to external router configuration
An SVI can be created for any VLAN that exists on the switch. Only one VLAN associates with one SVI.
Switch Virtual Interfaces
An SVI is “virtual” in that there is no physical port dedicated to the interface, yet it can perform the same functions for the VLAN as a router interface would 
Can be configured in much the same way as a router interface (IP address, inbound/outbound access control lists [ACLs], and so on). 
The SVI for the VLAN provides Layer 3 processing for packets to or from all switch ports associated with that VLAN.
By default, an SVI is created for the default VLAN (VLAN1) to permit remote switch administration.
Additional SVIs must be explicitly created and the number used corresponds to the VLAN tag associated.
Reasons to configure SVI
To provide a gateway for a VLAN so that traffic can be routed into or out of that VLAN
To provide fallback bridging if it is required for nonroutable protocols
To provide Layer 3 IP connectivity to the switch
To support routing protocol and bridging configurations
SVI: Advantages and Disadvantages
The following are some of the advantages of SVI:
It is much faster than router-on-a-stick because everything is hardware switched and routed.
No need for external links from the switch to the router for routing.
Not limited to one link. Layer 2 EtherChannels can be used between the switches to get more bandwidth.
Latency is much lower because it does not need to leave the switch.
The following are some of the disadvantages:
It needs a Layer 3 switch to perform inter-VLAN routing, which is more expensive
Routing with Routed Ports
A routed port is a physical port that acts similarly to a port on a traditional router with Layer 3 addresses configured. 
Unlike an access port, a routed port is not associated with a particular VLAN. A routed port behaves like a regular router interface. 
Also, because Layer 2 functionality has been removed, Layer 2 protocols.
Link Aggregation Control Protocol (LACP), which can be used to build either Layer 2 or Layer 3 EtherChannel bundles, would still function at Layer 3.
Routed ports are used for point-to-point links
Routed interfaces do not support subinterfaces as with Cisco IOS routers.
To configure routed ports, make sure to configure the respective interface as a Layer 3 interface using the no switchport interface command
Routed Ports: Advantages
Following are some of the advantages of routed ports:
A multilayer switch can have SVI and routed ports in a single switch. How is this an advantage of a routed port?
Multilayer switches forward either Layer 2 or Layer 3 traffic in hardware, so it helps to do routing faster.
Configuring Inter-VLAN Routing Using SVI and Routed Ports
Configuring Routing on a Multilayer Switch
Step 1. Create VLANs 10 and 20:
DSW1(config)# vlan 10
DSW1(config-vlan)# vlan 20
Step 2. On DSW1, enable IPv4 routing:
DSW1(config)# ip routing
Step 3. Configure SVI for VLANs with IP address
DSW1(config)# interface vlan 10
DSW1(config-if)# ip address 10.0.10.1 255.255.255.0
DSW1(config-if)# no shutdown
DSW1(config)# interface vlan 20
DSW1(config-if)# ip address 10.0.20.1 255.255.255.0
DSW1(config-if)# no shutdown
Configuring Routing on a Multilayer Switch
Step 4. Turn the interface that connects to R1 (Ethernet 0/0) into a routed interface and configure it with IP address.
DSW1(config)# interface ethernet 0/2
DSW1(config-if)# no switchport
*Nov 28 15:03:55.138: %LINK-3-UPDOWN: Interface Ethernet0/2, changed state to up
*Nov 28 15:03:56.142: %LINEPROTO-5-UPDOWN: Line protocol on Interface Ethernet0/2, changed state to up
DSW1(config-if)# ip address 10.0.99.1 255.255.255.0
Step 5. Configure a Routing Protocol
DSW1(config)# router eigrp 1
DSW1(config-router)# network 10.0.0.0
*Nov 28 15:12:22.448: %DUAL-5-NBRCHANGE: EIGRP-IPv4 1: Neighbor 10.0.99.2 (Ethernet0/2) is up: new adjacency
Using the SVI autostate exclude Command
The SVI interface is brought up when one Layer 2 port in the VLAN has had time to converge (transition from STP listening-learning state to forwarding state). 
The default action when a VLAN has multiple ports is that the SVI goes down when all ports in the VLAN go down. 
This action prevents features such as routing protocols from using the VLAN interface as if it were fully operational and minimizes other problems, such as routing black holes.
You can use the SVI autostate exclude command to configure a port so that it is not included in the SVI line-state up-and-down calculation.
Configuring autostate exclude
Switch(config)# interface interface slot/number
Switch(config-if)# switchport autostate exclude

This disables the SVI autostate and makes the SVI interface permanently active.
SVI Configuration Checklist
Identify which VLANs require a Layer 3 gateway.
Create a VLAN on a multilayer switch if it does not already exist.
Create an SVI interface for each VLAN.
Configure the SVI interface with an IP address.
Enable the SVI interface.
Enable IP routing on the multilayer switch.
Determine whether a dynamic routing protocol is needed.
Configure a dynamic routing protocol if needed.
Identify any switch ports that require autostate exclude.
Configure autostate exclude on identified switch ports.
Common Inter-VLAN Routing Problems
Troubleshooting Inter-VLAN Problems
Correct VLANs on all switches and trunks.
Correct routes.
Correct primary and secondary root bridges.
Correct IP address and subnet masks.

Layer 2 Versus Layer 3 EtherChannel
On a multilayer switch, you can configure Layer 2 or Layer 3 EtherChannels, depending on what type of devices that will be connected, and depending on their position in the network.
Layer 3 EtherChannel Configuration
Step 1. Create a virtual Layer 2 interface:
Switch(config)# interface port-channel 1
Step 2. Change interface to Layer 3 and enable the use of the ip address command:
Switch(config-if)# no switchport
Step 3. Assign an IP address to the port channel interface because this will now be a Layer 3 interface:
Switch(config-if)# ip address 172.32.52.10 255.255.255.0
Step 4. Navigate to the interface that is to be associated with the EtherChannel bundle. 
Switch(config)# interface range fastethernet 5/4 - 5
Layer 3 EtherChannel Configuration
Step 5. Remove the independent Layer 2 and Layer 3 functionality of the port so that the port can function as part of a group:
Switch(config-if-range)# no switchport
Switch(config-if-range)# channel-protocol pagp
Step 6. Assign all of the physical interfaces in the range to the EtherChannel group:
Switch(config-if-range)# channel-group 1 mode desirable
L3 EtherChannel Configuration Guidelines
The following are the guidelines for configuration for EtherChannel:
Speed and duplex: Configure all interfaces in an EtherChannel to operate at the same speed and in the same duplex mode.
Interface mode: Because the port channel interface is a routed port, the no switchport the same command must also be applied to the physical ports
Verifying the EtherChannel configuration: After EtherChannel is configured, use the following commands to verify and troubleshoot EtherChannel:
show interface port-channel channel-group-number
show etherChannel channel-group-number summary
show spanning-tree vlan vlan-number detail

Implementing DHCP
Explain the idea behind DHCP
Configure a DHCP server
Configure manual DHCP bindings
Configure a DHCP relay
Configure DHCP options
DHCP Overview
DHCP provides configuration parameters to Internet hosts. DHCP consists of two components: a protocol for delivering host-specific configuration parameters from a DHCP server to a host, and a mechanism for allocating network addresses to hosts.
DHCP is built on a client/server model in which designated DHCP server hosts allocate network addresses and deliver configuration parameters to dynamically configured hosts. 
Clients in access VLANs need DHCP services, and not only external servers but also routers can be used for DHCP services.
DHCP on MLS
Cisco multilayer switches running Cisco IOS Software include DHCP server and relay agent software. 
Distribution multilayer switches often act as Layer 3 gateways for clients connecting to the access switches on various VLANs. 
Therefore, the DHCP service can be provided directly by the distribution switches.
Alternatively, DHCP services can be concentrated in an external, dedicated DHCP server. 
In that case, distribution switches need to redirect the incoming clients’ DHCP requests to the external DHCP server.

Configuring DHCP in Multilayer Switched Network
Configuring DHCP in Multilayer Switched Network
DHCP Server
DSW1(config)# ip dhcp excluded-address 10.0.10.1
DSW1(config)# ip dhcp pool VLAN10POOL
DSW1(config-dhcp)# network 10.0.10.0 255.255.255.0
DSW1(config-dhcp)# default-router 10.0.10.1
DSW1(config-dhcp)# lease 2
Assign ip address to client
DSW1(dhcp-config)# host 10.0.10.200 255.255.255.0
DSW1(dhcp-config)# client-identifier 0063.6973.636f.2d61.6162.622e.6363.3030.2e30.3630.302d.4574.302f.30
Or
DSW1(dhcp-config)# hardware-address MAC-address
Configuring DHCP in Multilayer Switched Network
DHCP Discovery Process
In addition to these four messages, the following DHCP messages are displayed with debug output:
DHCPDECLINE: Message sent from the client to the server that the address is already in use.
DHCPNAK: The server sends a refusal to the client for request for configuration.
DHCPRELEASE: Client tells a server that it is giving up a lease.
DHCPINFORM: A client already has an IP address but is requesting other configuration parameters that the DHCP server is configured to deliver such as DNS address.
Configuring a DHCP Relay
A client that resides in VLAN 55 needs to have the following two configurations to forward the DHCP broadcast to the centralized server 192.168.1.244:
The multilayer switch must have a Layer 3 IP address that will receive the client DHCP request that is 10.0.55.1/24. This address may be a routed port or an SVI.
The ip helper-address command must be configured on the multilayer switch Layer 3 interface. With the DHCP relay address, when the switch receives a DHCP request in the form of a broadcast message from a client, the switch forwards this request, as a unicast message, to the IP address that is specified in the ip helper-address command. 
The ip helper-address command not only forwards DHCP UDP packets but also forwards TFTP, DNS, time, NetBIOS, name server, and BOOTP packets by default.
Configuring DHCP Options
Use DHCP options to “expand” the basic DHCP commands.
The following are some of the commonly used options.
Option 43: Vendor-encapsulated option that enables vendors to have their own list of options on the server. For example, you can use it to tell a lightweight access point where the Wireless LAN Controller (WLC) is. 
Option 69: SMTP server, if you want to specify available SMTP servers to the client.
Option 70: POP3 server, if you want to specify available POP3 servers to the client.
Option 150: TFTP server that enables your phones to access a list of TFTP servers.
Chapter 5 Summary
Inter-VLAN routing provides communication between the devices in different VLANs. Recall that a VLAN is a single broadcast domain, and the devices within a VLAN cannot communicate beyond VLAN boundaries unless through a Layer 3 device. Multilayer switches support two types of Layer 3 interfaces: routed ports and SVIs (VLAN interfaces).
Routed ports are point-to-point connections such as those that interconnect the building distribution submodules and the campus backbone submodules when using Layer 3 in the distribution layer.
SVIs are VLAN interfaces that route traffic between VLANs and VLAN group ports. In multilayer switched networks with Layer 3 in the distribution layer and Layer 2 in the access layer, SVIs can route traffic from VLANs on the access layer switches.
Chapter 5 Summary
Using router-on-a-stick is an alternative and legacy method of implementing inter- VLAN routing for low-throughput and latency-tolerant applications.
On multilayer switches, Layer 3 links can be aggregated using Layer 3 EtherChannels.
When a Layer 3 interface is configured, routing can be enabled.
DHCP server function can be configured on the Cisco switches and routers.
If the network uses a centralized DHCP server, a DHCP relay agent feature can be configured on the switches by using the ip helper-address command.
Chapter 5 Labs
CCNPv7.1 SWITCH Lab5.1 IVL-ROUTING
CCNPv7.1 SWITCH Lab5.2 DHCP4/6

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva5
Chapter 6: First-Hop Redundancy
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 6 Objectives
Overview of FHRP and HSRP
Configure and verify VRRP
Configure and verify GLBP
Overview of FHRP and HSRP
Overview of FHRP and HSRP
The need for first-hop redundancy protocols
HSRP overview
HSRP state transitions
Aligning HSRP with STP topology
Configuring and tuning HSRP
Load sharing with HSRP
Options HSRP has for tracking
Configuring HSRP interface tracking
Configuring object tracking in combination with HSRP
Configuring HSRP authentication
Tuning HSRP timers
The differences between HSRP Versions 1 and 2
The Need for First-Hop Redundancy
Network hosts are configured with a single default gateway IP address
If the router whose IP address serves as the default gateway to the network host fails, a network host will be unable to send packets to another subnet
The Need for First-Hop Redundancy
With first-hop router redundancy, a set of routers or Layer 3 switches work together to present the illusion of a single virtual router to the hosts on the LAN. 
By sharing an IP address and a MAC (Layer 2) address, two or more routers can act as a single “virtual” router
HSRP Overview
When frames are to be sent from the workstation to the default gateway, the workstation uses ARP to resolve the MAC address that is associated with the IP address of the default gateway. 
The ARP resolution will return the MAC address of the virtual router. 
Frames that are sent to the MAC address of the virtual router can then be physically processed by an active router that is part of that virtual router group.
The physical router that forwards this traffic is transparent to the network hosts.
The redundancy protocol provides the mechanism for determining which router should take the active role in forwarding traffic and determining when that role must be taken over by a standby router.
HSRP Overview
When the forwarding router or a link to it fails
The standby router stops seeing hello messages from the forwarding router.
The standby router assumes the role of the forwarding router.
As the new forwarding router assumes both the IP and MAC addresses of the virtual router, the end stations see no disruption in service.
HSRP Overview
HSRP active and standby routers send hello messages to multicast address 224.0.0.2 (all routers) for Version 1, or 224.0.0.102 for Version 2, using User Datagram Protocol (UDP) port 1985.
Hello messages are used to communicate between routers in the HSRP group. 
All the routers in the HSRP group need to be L2 adjacent so that hello packets can be exchanged.
HSRP Router Roles
All the routers in an HSRP group have specific roles and interact in specific manners:
■ Virtual router
An IP and MAC address pair that end devices have configured as their default gateway. 
The active router processes all packets and frames sent to the virtual router address. 
The virtual router processes no physical frames. There is one virtual router in an HSRP group.
■ Active router
Within an HSRP group, one router is elected to be the active router. 
The active router physically forwards packets sent to the MAC address of the virtual router. 
There is one active router in an HSRP group.
HSRP Router Roles
Standby router
Listens for periodic hello messages. When the active router fails, the other HSRP routers stop seeing hello messages from the active router. 
The standby router then assumes the role of the active router. There is one standby router in an HSRP group.
Other routers
There can be more than two routers in an HSRP group, but only one active and one standby router is possible. 
The other routers remain in the initial state, and if both the active and standby routers fail, all routers in the group contend for the active and standby router roles.
HSRP Active Router Operation
Router A assumes the active role and forwards all frames addressed to the assigned HSRP MAC address of 0000.0c07.acxx, where xx is the HSRP group identifier.
HSRP State Transition
HSRP State Transition
HSRP State Transition
When two routers participate in an election process, a priority can be configured to determine which router should become active. 
Without specific priority configuration, each router has a default priority of 100, and the router with the highest IP address is elected as the active router.
Regardless of other router priorities or IP addresses, an active router will stay active by default. 
A new election will occur only if the active router is removed. 
When the standby router is removed, a new election is made to replace the standby router. 
This behavior can change with the preempt option.
Aligning HSRP with STP Topology
It is a good practice to configure the same Layer 3 switch to be both the spanning-tree root and the HSRP active router for a single VLAN. 
This approach ensures that the Layer 2 forwarding path leads directly to the Layer 3 device that is the HSRP active gateway, thus achieving maximum efficiency.
Configuring and Tuning HSRP
Configuring and Tuning HSRP
Step 1. Configure R1’s Ethernet 0/1 (LAN-facing interface) with 192.168.1.3/24 IP address and HSRP standby IP of 192.168.1.1.
The IP of 192.168.1.1 is HSRP’s virtual IP address that is also configured as the default gateway IP address on PC 1 and PC 2:
R1(config)# interface ethernet 0/1
R1(config-if )# ip address 192.168.1.3 255.255.255.0
R1(config-if)# standby 1 ip 192.168.1.1
Step 2. Configure R2’s Ethernet 0/1 (LAN-facing interface) with 192.168.1.2/24 IP address and HSRP standby IP of 192.168.1.1.
Both R1 and R2 must have the same HSRP virtual IP address configured:
R2(config)# interface ethernet 0/1
R2(config-if)# ip address 192.168.1.2 255.255.255.0
R2(config-if)# standby 1 ip 192.168.1.1
Verify the ARP table
Step 3. On R1, verify the ARP table:
R1# show ip arp
Forwarding Through the Active Router
Make R2 the Active Router
Configure R2’s HSRP group 1 with priority of 110:
R2(config)# interface ethernet 0/1
R2(config-if)# standby 1 priority 110

Configure R1’s and R2’s Ethernet 0/1 HSRP group 1 interfaces with preemption:
R1(config)# interface ethernet 0/1
R1(config-if)# standby 1 preempt
R2(config)# interface ethernet 0/1
R2(config-if)# standby 1 preempt
Make R2 the Active Router
R2# show standby brief
Router R2 Failure Scenario
HSRP States After R2 Recover
Load Sharing with HSRP
Multigroup HSRP (MHSRP)
Multigroup HSRP (MHSRP)
The Need for Interface Tracking with HSRP
HSRP can track interfaces or objects and decrement priority if an interface or object fails. 
Interface tracking enables the priority of a standby group router to be automatically adjusted, based on the availability of the router interfaces. 
When a tracked interface becomes unavailable, the HSRP priority of the router is decreased. 
When properly configured, the HSRP tracking feature ensures that a router with an unavailable key interface will relinquish the active router role.
When the conditions that are defined by the object are fulfilled, the router priority remains the same. 
As soon as the verification that is defined by the object fails, the router priority is decremented. 
The amount of decrease can be configured. 
The default value is 10.
HSRP Interface Tracking
HSRP has a built-in mechanism for detecting link failures and starting the HSRP reelection process.
HSRP with Interface Tracking On
HSRP Tracking Configuration
R2(config)# interface ethernet 0/1
R2(config-if)# ip address 192.168.10.2
R2(config-if)# standby 10 ip 192.168.10.1
R2(config-if)# standby 10 priority 110
R2(config-if)# standby 10 preempt
R2(config-if)# standby 10 track ethernet1/1 20
HSRP Tracking Configuration Arguments
HSRP and Object Tracking
HSRP With Object Tracking
HSRP and Object Tracking Configuration
First, define an IP SLA ICMP echo test:
R2(config)# ip sla 10
R2(config-ip-sla)# icmp-echo 192.168.3.2
R2(config-ip-sla-echo)# frequency 5
R2(config-ip-sla-echo)# ip sla schedule 10 life forever start-time now
Then create an object and track the IP SLA instance:
R2(config)# track 100 ip sla 10
Then configure HSRP to track an object and decrement priority if the test fails:
R2(config)# interface ethernet 0/1
R2(config-if)# standby 1 track 100 decrement 20
Tracked objects
Tracked objects are defined in global configuration with the keyword track , followed by an object number. 
Although IP SLA is just one of the options that can be tracked, as shown in the following syntax, you can track up to 500 objects:
Switch(congi)# track 1 ?
interface 	Select an interface to track
ip 			IP protocol
list 		Group objects in a list
Tracked objects
Tracked objects offer a vast group of possibilities. 
A few options that are commonly available include the following
An interface
This performs a similar function like the HSRP interface tracking mechanism, but with advanced features. This tracking object can not only verify the interface status (line protocol) but also whether IP routing is enabled, whether an IP address is configured on the interface, and whether the interface state is up, before reporting to the tracking client that the interface is up.
IP route
A tracked IP-route object is considered up and reachable when a routing table entry exists for the route and the route is accessible. To provide a common interface to tracking clients, route metric values are normalized to the range of 0 to 255, where 0 is connected and 255 is inaccessible. You can track route reachability, or even metric values, to determine best-path values to the target network. 
Tracked objects (continue)
IP SLA
This special case allows you to track advanced parameters such as IP reachability, delay, or jitter.
A list of objects
You can track several objects and interrelate their results to determine whether one or several of them should trigger the “success” or “fail” condition.
Configuring HSRP Authentication
HSRP provides the following two types of authentication:
Plain text
Message digest 5 (MD5) algorithm

To configure plain-text authentication, use the following interface configuration command on HSRP peers:
Switch(config-if)# standby group authentication string

To configure MD5 authentication, use the following interface configuration command on HSRP peers:
Switch(config-if)# standby group authentication md5 key-string [ 0 | 7 ] string
Configuring HSRP Authentication
To configure MD5 authentication using key chains, use the following command sequence:
Switch(config)# key chain chain-name
Switch(config-keychain)# key key-number
Switch(config-keychain-key)# key-string [ 0 | 7 ] string
Switch(config-keychain-key)# exit
Switch(config)# interface interface-slot/number
Switch(config-if)# standby group authentication md5 key-chain chain-name
Tuning HSRP Timers
By default, the HSRP hello time is 3 seconds, and the hold time is 10 seconds, which means that the failover time could be as much as 10 seconds for clients to start communicating with the new default gateway. 
In some cases, this interval may be excessive for application support. 
The hello-time and the hold-time parameters are configurable. 
To configure the time between the hello messages and the time before other group routers declare the active or standby router to be nonfunctioning, enter this command in the interface configuration mode:
Switch(config-if)# standby [ group-number ] timers [ msec ] hellotime [ msec ] holdtime
Preemption Delay
Preemption is an important feature of HSRP that allows the primary router to resume the active role when it comes back online after a failure or a maintenance event. 
Preemption is a desired behavior as it forces a predictable routing path for the VLAN traffic during normal operations. 
It also ensures that the Layer 3 forwarding path for a VLAN parallels the Layer 2 STP forwarding path whenever possible.
When a preempting device is rebooted, HSRP preemption communication should not begin until the distribution switch has established full connectivity to the rest of the network. 
This situation allows the routing protocol convergence to occur more quickly, after the preferred router is in an active state.
To accomplish this, measure the system boot time and set the HSRP preemption delay to a value that is about 50 percent greater than device’s boot time
Configuring HSRP Preemption Delay Timers
For example, if the boot time for the distribution device is 150 seconds, the preempt delay should be set to 225 seconds
HSRP Versions
There are two HSRP versions available on most Cisco routers and Layer 3 switches:
HSRPv1 and HSRPv2.
Version 1 is a default version on Cisco IOS devices. 
HSRPv2 allows group numbers up to 4095, thus allowing you to use VLAN number as the group number.
HSRP Version 2 must be enabled on an interface before HSRP IPv6 can be configured.
HSRP Version 2 will not interoperate with HSRP Version 1. 
All devices in an HSRP group must have the same version configured; otherwise, the hello messages are not understood. 
HSRP Versions
An interface cannot operate both Version 1 and Version 2 because they are mutually exclusive.
The MAC address of the virtual router and the multicast address for the hello messages are different with Version 2. 
HSRPv2 uses the new IP multicast address 224.0.0.102 to send the hello packets instead of the multicast address of 224.0.0.2, which is used by Version 1. 

To enable HSRP Version 2, enable the following configuration:
Switch(config-if) standby hsrp-number version 2


Configuring Layer 3 Redundancy with VRRP
Upon completing this section, you will be able to do the following:
Describe the idea behind VRRP
Configure and verify VRRP
Describe the differences between HSRP and VRRP
Describe tracking options with VRRP
Configure VRRP interface object tracking
About VRRP
VRRP is an open standard alternative to HSRP. 
VRRP is similar to HSRP, both in operation and configuration. 
The VRRP master is analogous to the HSRP active gateway, and the VRRP backup is analogous to the HSRP standby gateway. 
A VRRP group has one master device and one or multiple backup devices. 
A device with the highest priority is the elected master. Priority can be a number between 0 and 255. 
Priority value 0 has a special meaning; it indicates that the current master has stopped participating in VRRP.
This setting is used to trigger backup devices to quickly transition to master without having to wait for the current master to time out.
About VRRP
VRRP differs from HSRP in that it allows you to use an address of one of the physical VRRP group members as a virtual IP address. 
In this case, the device with the used physical address is a VRRP master whenever it is available.
The master is the only device that sends advertisements (analogous to HSRP hellos).
Advertisements are sent to the 224.0.0.18 multicast address, protocol number 112. 
The default advertisement interval is 1 second. The default hold time is 3 seconds. 
HSRP, in comparison, has the default hello timer set to 3 seconds and the hold timer to 10 seconds. 
Like with HSRP, load sharing is also available with VRRP. Multiple virtual router groups can be configured
Contrary to HSRP, preemption is enabled by default with VRRP.

About VRRP
HSRP and VRRP Differences
Configuring VRRP and Spotting the Differences from HSRP
IP Addressing for the VRRP Configuration
Configuring VRRP
Step 1. Configure R1’s Ethernet 0/1 with IP address 192.168.1.3 and VRRP virtual IP address 192.168.1.1:
R1(config)# interface ethernet 0/1
R1(config-if)# ip address 192.168.1.3 255.255.255.0
R1(config-if)# vrrp 1 ip 192.168.1.1
Configure R2’s Ethernet 0/1 with IP address of 192.168.1.2 and VRRP virtual IP address of 192.168.1.1:
R2(config)# interface ethernet 0/1
R2(config-if)# ip address 192.168.1.2 255.255.255.0
R2(config-if)# vrrp 1 ip 192.168.1.1
Step 2. Configure R2’s Ethernet 0/1 with VRRP priority of 110:
R2(config-if)# vrrp 1 priority 110
Verify the VRRP Status
VRRP and Authentication
Configure MD5 authentication for VRRP on R1’s Ethernet 0/1 interface:
R1(config)# interface ethernet 0/1
R1(config-if)# vrrp 1 authentication md5 key-string MyVRRP
%VRRP-4-BADAUTHTYPE: Bad authentication from 192.168.1.2, group 1, type 0, expected 254.
Configure MD5 authentication for VRRP on R2’s Ethernet 0/1 interface:
R2(config)# interface ethernet 0/1
R2(config-if)# vrrp 1 authentication md5 key-string MyVRRP
R1’s CLI:
%VRRP-6-STATECHANGE: Et0/1 Grp 1 state Master -> Backup
Tracking and VRRP
VRRP does not have a native interface tracking mechanism but it does have the ability to track objects.
Tracking and VRRP Configuration
Create a tracked object, where the status of the uplink interface is tracked:
R2(config)# track 1 interface ethernet 0/0 line-protocol
Configure VRRP to track previously created object and decrease VRRP priority by 20 should the uplink fail:
R2(config)# interface ethernet 0/1
R2(config-if)# vrrp 1 track 1 decrement 20

Configuring Layer 3 Redundancy with GLBP
Upon completing this section, you will be able to do the following:
Describe the basic idea behind GLBP
Compare GLBP to HSRP
Describe the possible states of GLBP virtual gateway and virtual forwarder
Configure and verify GLBP
Understand GLBP operations
List and describe GLBP load-balancing options
Secure GLBP using authentication
Describe GLBP behavior in VLANs with running STP
Describe the system of weights and decrements in GLBP

Introducing GLBP
GLBP shares some concepts with VRRP and HSRP, but the terminology differs, and its behavior is more dynamic and robust.
Although HSRP and VRRP provide gateway resiliency only the active router within the group forwards the traffic for the virtual MAC. 
HSRP and VRRP can accomplish load sharing by manually specifying multiple groups and assigning multiple default gateways. 
GLBP is a Cisco proprietary solution that allows for automatic selection and simultaneous use of multiple available gateways, in addition to automatic failover between those gateways. 
Multiple routers share the load of packets that, from a client’s perspective, are sent to a single default gateway address.
There is also no need to configure a specific gateway address on an individual host. All hosts can use the same default gateway.
GLBP Roles
GLBP routers are divided into two roles: a gateway and a forwarder:
GLBP AVG (active virtual gateway)
Members of a GLBP group elect one gateway to be the AVG for that group. 
Other group members provide a backup for the AVG when the AVG becomes unavailable; these will be in standby state. 
The AVG assigns a virtual MAC address to each member of the GLBP group. 
The AVG listens to the ARP requests for the default gateway IP and replies with a MAC address of one of the GLBP group members, thus load sharing traffic among all the group members.
GLBP AVF (active virtual forwarder)
Each gateway assumes responsibility for forwarding packets that are sent to the virtual MAC address that is assigned to that gateway by the AVG. 
These gateways are known as AVFs. There can be up to four forwarders within a GLBP group. 
All other devices will be secondary forwarders, serving as backup if the current AVF fails. 
Forwarders that are forwarding traffic for a specific virtual MAC are in the active state and are called AVFs. Forwarders that are serving as backups are in the listen state.
Comparing GLPB to HSRP
GLBP States
GLBP States (Gateway)
Following are the possible virtual gateway states:
Disabled: The virtual IP address has not been configured or learned, but there is some GLBP configuration.
Initial: The virtual IP address has been configured or learned, but configuration is not complete. The interface must be operational on Layer 3 and configured to route IP.
Listen: The virtual gateway is receiving hello packets. It is ready to change to speak state if the active or standby virtual gateway becomes unavailable.
Speak: The virtual gateway is trying to become the active or standby virtual gateway.
Standby: This gateway is next in line to be the active virtual gateway.
Active: This gateway is the AVG, and is responsible for responding to ARP requests for the virtual IP address.
GLBP States (Forwarder)
The following are the possible virtual forwarder states:
Disabled: The virtual MAC address has not been assigned or learned. The disabled virtual forwarder will be deleted shortly. This state is transitory only.
Initial: The virtual MAC address is known but configuration of virtual forwarder is not complete. The interface must be operational on Layer 3 and configured to route IP.
Listen: This virtual forwarder is receiving hello packets and is ready to change to the active state if the active virtual forwarder becomes unavailable.
Active: This gateway is the AVF, and is responsible for forwarding packets sent to the virtual forwarder’s MAC address.
Configuring and Verifying GLBP
IP Addresses Used in GLBP Configuration
GLBP Configuration
Configure R1’s Ethernet 0/1 with IP address of 192.168.1.3 and GLBP virtual IP address of 192.168.1.1:
R1(config)# interface ethernet 0/1
R1(config-if)# ip address 192.168.1.3 255.255.255.0
R1(config-if )# glbp 1 ip 192.168.1.1
Configure R2’s Ethernet 0/1 with IP address of 192.168.1.2 and GLBP virtual IP address of 192.168.1.1:
R2(config)# interface ethernet 0/1
R2(config-if)# ip address 192.168.1.2 255.255.255.0
R2(config-if)# glbp 1 ip 192.168.1.1
GLBP Configuration
Configure R1’s Ethernet 0/1 with GLBP priority of 110 and enable preemption for both GLBP routers:
R1(config)# interface ethernet 0/1
R1(config-if)# glbp 1 priority 110
R1(config-if)# glbp 1 preempt

R2(config)# interface ethernet 0/1
R2(config-if)# glbp 1 preempt
The virtual MAC addresses of GLBP
The virtual MAC addresses of GLBP are in the form of 0007.b4XX.XXYY. 
XXXX is a 16-bit value that represents six 0 bits, followed by a 10-bit GLBP group number. 
YY is an 8-bit value, and it represents the virtual forwarder number. 
The AVG assigned forwarder 1 virtual MAC address of 0007. b400.0101 and forwarder 2 virtual MAC address of 0007.b400.0102
GLBP Final Configuration
GLBP Operation (ARP Request)
GLBP Operation (ARP Reply)
GLBP Operation (Traffic Flow)
GLBP Operations: Failed R1 New Data Path
GLBP Load-Balancing Options
GLBP supports the following operational modes for load balancing traffic across multiple default routers that are servicing the same default gateway IP address:
Weighted load-balancing algorithm
The amount of load that is directed to a router depends on the weighting value that is advertised by that router.
Host-dependent load-balancing algorithm
A host is guaranteed the use of the same virtual MAC address as long as that virtual MAC address is participating in the GLBP group.
Round-robin load-balancing algorithm
As clients send ARP requests to resolve the MAC address of the default gateway, the reply to each client contains the MAC address of the next possible router in a round-robin fashion. The MAC addresses of all routers take turns being included in address resolution replies for the default gateway IP address.
To configure the load-balancing option, use the following command:
Switch(config-if)# glbp group load-balancing [ round-robin | weighted | host-dependent ]
GLBP Authentication
The key for the MD5 hash can either be given directly in the configuration using a key string or supplied indirectly through a key chain. 
The key string cannot exceed 100 characters in length. 
The following example demonstrates the configuration for GLBP authentication:
Router(config)# interface Ethernet0/1
Router(config-if)# ip address 10.0.0.1 255.255.255.0
Router(config-if)# glbp 1 authentication md5 key-string d00b4r987654321a
Router(config-if)# glbp 1 ip 10.0.0.10
GLBP and STP
With some switching topologies, the operation of STP results in inefficient traffic paths.
In such cases, implementation of HSRP might be preferred over GLBP because it is easier to understand, whereas GLBP provides no advantages.
Tracking and GLBP
Changing weight affects the AVF election and the load-balancing algorithm. 
Both values can be manipulated with object tracking.
GLBP Weight
GLBP uses a weighting scheme to determine the forwarding capacity of each router in the GLBP group. 
The weighting that is assigned to a router in the GLBP group can be used to determine whether it will forward packets and, if so, the proportion of hosts in the LAN for which it will forward packets. 
Thresholds can be set to disable forwarding when the weighting for a GLBP group falls below a certain value, and when it rises above another threshold, forwarding is automatically reenabled.
By default, the GLBP virtual forwarder preemptive scheme is enabled with a delay of 30 seconds. 
A backup virtual forwarder can become the AVF if the current AVF weighting falls below the low weighting threshold for 30 seconds. 
To disable the GLBP forwarder preemptive scheme, use the no glbp forwarder preempt command or change the delay by using the glbp forwarder preempt delay minimum command.
GLBP Tracking Detects Interface Failure
GLBP Weighing Option Under Failures
GLBP Object Tracking Sample Configuration
Chapter 6 Summary
The redundancy protocol provides the mechanism for determining which router should take the active role in forwarding traffic and determining when that role must be taken over by a standby router .
HSRP is a Cisco proprietary protocol, whereas VRRP is an industry standard for virtual routing gateways.
HSRP Version 1 and Version 2 active and standby routers send hello messages to multicast address 224.0.0.2 for Version 1 and 224.0.0.102 for Version 2 on UDP port 1985.
It is important that the configured active router should be the same as the STP root bridge.
HSRP and VRRP use the VLAN load-balancing mechanism for load balancing.
With the new RFC, only the Cisco implementation of VRRP supports VRRP authentication.
GLBP, by default, provides the virtual gateway and load balancing via multiple virtual MAC addresses.
Review all the configuration examples and troubleshooting steps for better understanding and for exam preparation.
Chapter 6 Labs
CCNPv7.1 SWITCH Lab6.1 FHRP HSRP VRRP
CCNPv7.1 SWITCH Lab6.2 HSRPv6
CCNPv7.1 SWITCH Lab6.3 GLBP

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva6

Chapter 7: Network Management
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 7 Objectives
This chapter covers the following topics related to network management and mobility:
AAA
Identity-based networking 802.1X
NTP
SNMP
AAA
AAA
■ Authentication
Authentication is the process of identifying a user before that user is allowed access to a protected resource. 
■ Authorization
After the user gains access to the network, authorization is performed. 
Authorization allows you to control the level of access users have.
■ Accounting
Accounting is performed after authentication. Accounting enables you to collect information about the user activity and resource consumption.
AAA Benefits
Increased flexibility and control of access configuration
AAA offers additional authorization flexibility on a per-command or per-interface level, which is unavailable with local credentials.
Scalability
As the network grows, managing a large number of users on multiple devices becomes highly impractical and error-prone, with a lot of administrative burden.
Standardized authentication methods
AAA supports the RADIUS protocol, which is an industry open standard. This ensures interoperability and allows flexibility because you can mix and match different vendors.
Multiple backup systems
You may specify multiple servers when configuring authentication options on the method list, combining them in a server group.
RADIUS and TACACS+ Overview
RADIUS and TACACS+ are AAA protocols. 
Both use the client/server model. 
As shown in Step 1, a user or machine sends a request to a networking device such as a router that acts as a network access server when running AAA. 
The network access server then communicates (2, 3) with the server exchanging RADIUS or TACACS+ messages. 
If authentication is successful, the user is granted (4) an access to a protected resource (5), such as a device CLI, network, and so on. 
TACACS+ Versus RADIUS
RADIUS Authentication Process
TACACS+ Authentication Process
Configuring AAA
To enable AAA, the first step is to configure the aaa new-model command in global configuration mode. 
This step essentially enables AAA capability. 
In addition, until this command is enabled, all other AAA commands are hidden.

The aaa new-model command immediately applies local authentication to all lines and interfaces (except console line con 0). 
To avoid being locked out of the router, it is a best practice to define a local username and password before starting the AAA configuration.
Configuring RADIUS Access
Switch(config)# radius server configuration-name
Switch(config-radius-server)# address ipv4 hostname [auth-port integer ] [ acct-port integer]
Switch(config-radius-server)# key string
Switch(config)# aaa group server radius group-name
Switch(config-sg-radius)# server name configuration-name
Apply RADIUS Method List to vty
Switch(config)# aaa authentication login radius_list group Mygroup2 local
Switch(config)# line vty 0
Switch(config-line)# login authentication radius_list
Configuring TACACS+ for Console and vty Access
Switch(config)# tacacs server configuration-name
Switch(config-server-tacacs)# address ipv4 hostname
Switch(config-server-tacacs)# port integer
Switch(config-server-tacacs)# key string
Switch(config)# aaa group server tacacs+ group-name
Switch(config-sg-tacacs+)# server name configuration-name
AAA Authorization
To configure authorization, complete the following steps:
Step 1. Define a named list of authorization methods.
Step 2. Apply that list to one or more interfaces (except for the default method list).
Step 3. The first listed method is used. If it fails to respond, the second one is used, and so on until all listed methods are exhausted. Once the method list is exhausted, a failure message is logged.

Switch(config)# aaa authorization authorization-type list-name method-list
Switch(config)# line line-type line-number
Switch(config)# authorization { arap | commands level | exec | reverse-access } list-name
AAA Accounting
AAA accounting has the same rules and configuration steps as authentication and authorization:
Step 1. You must first define a named list of accounting methods.
Step 2. Apply that list to one or more interfaces (except for the default method list).
Step 3. The first listed method is used; if it fails to respond, the second one is used, and so on.

Switch(config)# aaa accounting accounting-type list-name { start-stop | stop-only | none } method-list
Switch(config)# interface interface-type interface-number
Switch(config-if)# ppp accounting list-name
Limitations of TACACS+ and RADIUS
RADIUS may not be the optimal choice in the following situations:
Device-to-device situations
RADIUS does not offer two-way authentication. 
Networks using multiple service
RADIUS generally binds a user to a single service model. 

TACACS+ may not be the optimal choice in the following situations:
Multivendor environment
TACACS+ is a Cisco proprietary protocol 
When speed of response from the AAA services is of concern
TACACS+ uses TCP as a transport protocol mechanism. 

Identity-Based Networking
Identity-based networking is a concept that unites several features to include authentication, access control, mobility, and user policy components with the aim to provide and restrict users with the network services that they are entitled to.
From a switch perspective, identity-based networking allows you to verify users once they connect to a switch port..
IEEE 802.1X Port-Based Authentication Overview
Until the client is authenticated, 802.1X access control allows only EAPOL, Cisco Discovery Protocol (CDP), and Spanning Tree Protocol (STP) traffic to pass through the port to which the client is connected. After authentication is successful, normal traffic can pass through the respective port.
802.1X Client/Server Model
Client
Usually a workstation or laptop with 802.1X-compliant client software. 
Most modern operating systems include native 802.1X support. 
The client is also referred to as a supplicant in 802.1X terminology.
Authenticator
Usually an edge switch or wireless access point (AP), the authenticator controls the physical access to the network based on the authentication status of the client. 
Authenticator includes a RADIUS client, which is responsible for encapsulation and decapsulation of Extensible Authentication Protocol (EAP) frames and interaction with the authentication server. 
Authentication server
A server that performs the actual authentication of the client. 
Currently, a RADIUS server with EAP extensions is the only supported authentication server.
802.1X Port-Based Authentication Overview
802.1X Configuration Example
You will not be able to issue dot1x commands on the interface if it is not set to switchport mode access prior. 
The default state of switch ports varies between switches, but it is not commonly set to the access mode.

The Need for Accurate Time
The need for accurate time is increasing year by year. 
Coordinating events, marking logs, and kicking-off scripts all run based on a system clock. 
Therefore, in today’s network, coordination of system clocks and their accuracy is increasing in importance.
From a best practice perspective, it is recommended to set clocks on all network devices to UTC regardless of their location, and then configure the time zone to display the local time if desired. In this manner, global operations can fall back to UTC time for relative time.
Configuring the System Clock Manually
Setting Summer Time
clock summer-time zone recurring [ week day month hh:mm week day month hh:mm [offset]]

clock summer-time zone date date month year hh:mm date month year hh:mm [ offset ]

clock summer-time zone date month date year hh:mm month date year hh:mm [ offset ]
Setting Summer Time
Network Time Protocol Overview
Manually setting the clocks of any network device is neither accurate nor scalable. 
The best practice is to use Network Time Protocol (NTP), Simple NTP (SNTP), or Precision Time Protocol (PTP)
NTP is designed to synchronize the time throughout an entire network infrastructure, including servers, switches, routers, host machines, wireless access points, uninterruptible power supply (UPS), and so on. 
NTP leverages UDP port 123 for both the source and destination by default.
Network Time Protocol Overview
An NTP network usually gets its reference time from an authoritative time source, such as a radio clock, GPS, or an atomic clock attached to an NTP time server somewhere in the network. 
NTP then distributes this time across the network.
Accurate timekeeping is made possible by exchanging NTP messages between each pair of machines (server/client) with an association. 
However, in a LAN environment, NTP can be configured to use IP broadcast messages instead.
To keep accuracy of time, NTP uses the concept of a stratum to describe how many NTP hops away a machine is from an authoritative time source.
A machine running NTP automatically chooses the machine with the lowest stratum number
NTP: Stratum
NTP avoids in two ways synchronizing to a machine whose time may not be accurate. 
NTP never synchronizes to a machine that is not synchronized itself.
NTP compares the time that is reported by several machines and will not synchronize to a machine whose time differs significantly from the others, even if its stratum is lower. 
NTP Modes
A device may take on more than one role at a time.
Server
Provides accurate time information to clients on the network.
Client
Synchronizes its time to an NTP server. This mode is most suited for file	server and workstation clients that are not required to provide any form of time synchronization to other local clients. It can also provide accurate time to other devices.
Peers
Peers only exchange time synchronization information.
Broadcast/multicast
Special “push” mode of NTP server where the local LAN is flooded with updates; used only when time accuracy is not an issue.
NTP Example
Verify NTP
Setting and Verifying the Clock Time Zone and Daylight Savings Time 
Downstream NTP Example


NTP Design Principles
Securing NTP
NTP authentication steps:
Step 1. Define NTP authentication key or keys with ntp authentication-key command. Every number specifies a unique NTP key.
Step 2. Enable NTP authentication using the ntp authenticate command.
Step 3. Tell the Cisco device which keys are valid for NTP authentication using the ntp trusted-key command. The only argument to this command is the key that you defined in the first step.
Step 4. Specify the NTP server that requires authentication by using the ntp server ip-address key key-number command. You can similarly authenticate NTP peers by using the ntp peer ip-address key key-number command.
NTP Authentication Example
NTP ACL’s
For NTP, you can configure the following four restrictions through access lists:
Peer
Time synchronization requests and control queries are allowed. The device is allowed to synchronize itself to remote systems that pass the access list.
Server: 
Time synchronization requests and control queries are allowed. The device is not allowed to synchronize itself to remote systems that pass the access list.
Server-only
Only allows synchronization requests.
Query-only
Only allows control queries.
NTP Access List Example
NTP Source Address
The source of the NTP packet will be the same as the interface the packet was sent out on. 
When implementing authentication and access lists, it is good to have a specific interface set to act as the source interface for NTP.
It would be wise of you to choose a loopback interface to use as the NTP source. 
This is because the loopback will never be down like physical interfaces.
If you configured loopback 0 to act as the NTP source for all communication and that interface has, for example, an IP address of 192.168.12.31, you can write up just one access list that will allow or deny based on one single IP address of 192.168.12.31.
NTP Versions
NTPv4 is an extension of NTP Version 3. NTPv4 supports both IPv4 and IPv6 and is backward compatible with NTPv3.
NTPv4 adds the following capabilities:
Support for IPv6
Better security
Leverages multicast over broadcast for push modes

SNMP
This subsection covers the following topics related to SNMP:
The role of SNMP
Different SNMP versions
Recommended practices for setting up SNMP
Configuration examples for SNMP Version 3
Verifying SNMP configurations
SNMP Overview
SNMP systems consist of two components, as follows:
The SNMP manager that periodically polls the SNMP agents on managed devices by querying the device for data. Periodic polling has a disadvantage: A delay occurs between an actual event occurrence and the time the SNMP manager polls the data.
SNMP agents on managed devices collect device information and translate it into a compatible SNMP format according to the MIB. MIBs are collections of definitions of the managed objects. SNMP agents keep the database of values for definitions written in the MIB.
SNMP Process
SNMP Versions
Version 1
Introduced five message types
Get Request,
Get Next Request
Set Request
Get Response
Trap. 
This version is rarely used nowadays.
Version 2 
Introduced two new message types
Get Bulk Request to poll large amounts of data,
Inform Request, a type of trap with expected acknowledgment on receipt. 
Version 2 added 64-bit counters to accommodate faster network interfaces.
Added a complex security model, which was never widely accepted.
Version 2c
Community-based SNMP Version 2, is wide accepted
Community-based version of SNMP is very unsecure. 
Version 3 
Methods to ensure the secure transmission of critical data between the manager and agent were added.
SNMPv3 Security
SNMPv3 supports the following three levels of security:
noAuthNoPriv
No authentication is required, and no privacy (encryption) is provided.
authNoPriv
Authentication is based on Hashed Message Authentication Code (HMAC), MD5, or Secure Hash (SHA). No encryption is provided.
authPriv
In addition to authentication, cipher block chaining - Data Encryption Standard (CBC-DES) encryption is used.
SNMP Best Practices
Restrict access to read-only.
Use write access with separate credentials and careful consideration.
Set up SNMP views to restrict manager to only access needed sets of MIBs.
Configure ACLs to restrict SNMP access only by known managers.
Use SNMPv3 authentication, encryption, and integrity where possible, including upgrading devices to support SNMPv3 if necessary.
SNMPv3 Configuration Steps
Step 1. Configure an access list to be used to restrict subnets for SNMP access.
Step 2. Configure the SNMPv3 views to limit access to specific MIBs.
Step 3. Configure the SNMPv3 security groups.
Step 4. Configure the SNMPv3 users.
Step 5. Configure the SNMPv3 trap receivers.
Step 6. Configure ifindex persistence to prevent ifindex changes.
SNMPv3 Best Practice Configuration
SNMP Command Reference
Chapter 7 Summary
The AAA features include authentication, authorization, and accounting. The use of AAA is required in nearly all campus networks because it secures and provides administrative control and logging of user access to network devices and to the network itself.
Identity-based networking leverages protocols such as 802.1X to support mobility, security, authentication, and authorization of users to network resources.
Accurate time is essential for time logging services in campus networks, as are many security features like encryption.
All Cisco Catalyst switches support NTP for time synchronization.
NTP generally achieves millisecond accuracy in LAN networks.
SNMP is a lightweight protocol that not only monitors and controls devices but also supports alerting of events.
SNMPv3 is the best practice recommendation for SNMP; avoid using SNMPv2 (or v1) if it all possible (because of its lack of security features).
Security around SNMP must be considered as part of any implementation plan. At a minimum, use authentication and encryption along with restricted write access and IP ACLs to restrict network access.
Chapter 7 Labs
CCNPv7.1 SWITCH Lab7.1 NTP
CCNPv7.1 SWITCH Lab7.2 SNMP

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva7


Switching Features andTechnologies for the Campus Network
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 8 Objectives
This chapter covers the following Cisco Catalyst switch features:
Discovery protocols
Unidirectional Link Detection
Power over Ethernet
SDM templates
Monitoring features
IP SLA
Discovery Protocols
Discovery Protocols
This section on discovery protocols covers the following topics:
Introduction to LLDP and comparison to CDP
Basic configuration of LLDP
Discovering neighbors using LLDP
Introduction to LLDP
LLDP is an industry standard protocol for neighbor discovery. 
All current Cisco devices support LLDP, and only legacy and end-of-sale platforms may not support LLDP.
Introduction to LLDP
This protocol can advertise details such as configuration information, device capabilities, IP address, hostname, and device identity. 
LLDP is used for a plethora of information sharing, it is not architected to send out real-time information such as performance data or counter data.
An advantage of LLDP over CDP is that it allows for customization. LLDP can carry a lot of information that is relevant to your network. 
One drawback of LLDP in comparison to CDP is that it is not very lightweight.
Introduction to LLDP
The following list captures a few important implementation properties of LLDP:
LLDP is unidirectional.
LLDP operates only in an advertising mode.
LLDP does not solicit for information or monitor state changes between LLDP nodes.
LLDP leverages a Layer 2 multicast frame to notify neighbors of itself and its properties.
LLDP will receive and record all information it receives about its neighbors.
LLDP uses 01:80:c2:00:00:0e, 01:80:c2:00:00:03, or 01:80:c2:00:00:00 as the destination multicast MAC address.
Introduction to LLDP
The following list defines the most common information exchanged with LLDP with campus switches:
System name and description
Port name and description
Port VLAN and VLAN name
Management IP address
System Capabilities (Wi-Fi, routing, switching, and so on)
Power over Ethernet
Link aggregation
Basic Configuration of LLDP
CDP is enabled by default on all Cisco devices, but LLDP may be either enabled or disabled by default, depending on the hardware platform and software version. 
Therefore, to enable LLDP on a device, use the command lldp run in global configuration mode. To disable it, use no lldp run. 
To disable LLDP on a specific interface, you need to disable both LLDP from receiving or transmitting LLDP by issuing both the no lldp receive and no lldp transmit commands.
Basic Configuration of LLDP
LLDP Neighbors
LLDP Traffic Info
LLDP Key Features
LLDP allows network management applications to automatically discover and learn about network devices.
LLDP is the industry standard alternative to the CDP.
LLDP supports enabling or disabling either transmitting or receiving capabilities per port.
To view LLDP neighbors, use the show lldp neighbors [ detail ] command.

UDLD
UDLD
The unidirectional condition at Layer 2 is disastrous for any network because it will lead to either spanning tree not blocking on a forwarding port or a routing black hole.
In either of these situations, the network will exhibit a total failure, become instable, and eventually create a complete loss of connectivity for end users.
UDLD may protect the network from the following problems:
Transient hardware condition
Hardware failure
Optic/GBIC anomalous behavior or failure
Miswired cabling
Software defect or condition
Misconfigured or malfunction of inline tap or sniffer	
UDLD Mechanisms and Specifics
UDLD is supported on all current Cisco Catalyst and Nexus switches. 
UDLD functions by transmitting Layer 2 packets to the well-known MAC address 01:00:0C:CC:CC:CC.
If the packets are not echoed back within a specific time frame, the link is flagged as unidirectional.
Devices on both ends of the link must support UDLD for the protocol to successfully identify and disable unidirectional links.
UDLD messages are sent at regular intervals. 
This timer can be modified. 
The default setting varies between platforms; however, the typical value is 15 seconds.
UDLD Behavior
The behavior of UDLD after it detects a unidirectional link is dependent on its operation mode, either normal mode or aggressive mode. The modes are described as follows:
Normal mode
When a unidirectional link is detected the port is allowed to continue its operation. UDLD just marks the port as having an undetermined state. A syslog message is generated.
Aggressive mode
When a unidirectional link is detected the switch tries to reestablish the link. It sends one message a second, for 8 seconds. If none of these messages are sent back, the port is placed in error-disabled state.
UDLD Configuration
To configure a Cisco Catalyst switch for UDLD normal mode, use the udld enable command.
Similarly, to enable UDLD in aggressive mode, use the udld aggressive keyword.
To display the UDLD status for the specified interface or for all interfaces, use the show udld [ interface slot/number ] privileged EXEC command. 
To view UDLD neighbors, use the show udld neighbors .
In addition, use udld reset command to reset all the interfaces that were shut down by UDLD. 
You can also achieve a UDLD reset by first shutting down the interface and then bringing it back up (that is, shut , then no shut ).
Loop Guard and UDLD Functionality Comparison

Power over Ethernet
Power over Ethernet (PoE) supplies power through the same cable as data.
PoE benefits
PoE switches support remote management where power adapters and injectors do not.
PoE switches allow for centralized methods of backup power.
PoE requires less configuration than a local power adapter or injector.
PoE leverages the data cabling infrastructure, and no additional power cable is required as with the case with power adapters or injectors.
PoE Components
PoE terminology refers to three types of components:
Power-sourcing devices
Cisco Catalyst switches and power injectors
Powered devices
Access points, IP phones, and IP cameras.
Thin clients, sensors, wall clocks, and so on. 
Even switches can be powered through PoE itself.
Ethernet cabling. 
As with standard Ethernet, the distance of PoE is limited to 100 meters with Category 5 cabling.
PoE Standards
IEEE 802.3af (ratified 2003)
This standard provides interoperability between different vendors. 
Up to 15.4 W of DC power is available for each powered device.
IEEE 802.3at (ratified 2009)
This standard is an improvement over the 802.3af standard, and can provide powered devices with up to 25.5 W of power.
This number can be increased to 50 W and more with implementations that are outside the standard. 
This standard is also known as PoE+ or PoE Plus.
PoE Negotiation
The Cisco switches do not supply power to a port unless it specifically detects the need by the end device. 
This prevents wasting of unnecessary power and so on.
With 802.3af and 802.3at, the switch tries to detect the powered device by supplying a small voltage across the Ethernet cable. 
The switch then measures the resistance. If the measured resistance is 25K ohm, a powered device is present. 
The powered device can provide the switch with a power class information. 
The default class of 0 is used if either the switch or the powered device does not support power class discovery
PoE Power Classes
Configuring and Verifying PoE
SDM Templates
SDM Templates
Upon completing this section on SDM templates, you will be able to do the following:
Describe the typical SDM template types
Change the SDM template
Describe precautions to take when changing the SDM templates
SDM Template Types
SDM templates modify system resources such as CAM and TCAM.
SDM templates:
Default
The default template; this template provides for a mix of unicast routes, connected, and host routes.
Routing
As one example, you would enable this template if the device is performing routing in the distribution or core of the network. The device is able to carry numerous routes, but only for IPv4.
Access
You would enable this template if you have many VLANs. In turn, this template reduces the resources that are allocated to routing.
SDM Template Types
VLAN
When you enable this template, you allocate most of the table space to Layer 2 unicasts. You would use this when you have large subnets with many MAC addresses.
Dual IPv4 and IPv6
You would enable this template if you want to turn on the IPv6 capabilities of the device. When enabling this template, you have to choose between default, routing, and VLAN:
Default
More space is reserved for IPv6 routing and security. There is less reserved space for Layer 2 unicast.
Routing
More space is reserved for IPv6 routing than IPv4 routing.
VLAN
Suitable for when you are running a dual-stack environment with lots of VLANs.

Displaying SDM Resources
Choosing the Right SDM Template
It is a best practice to change the SDM template only if you have a good reason to do so. 
Before changing the template, investigate whether the change is needed or if it is just a workaround for poor design choices. 
As another best practice, always investigate the amount of systems resources being used prior to considering changes to the SDM template. 
To verify how much of the system resources are being used, use the command show platform tcam utilization . 
If the TCAM utilization is close to maximum for any of the parameters, check if any of the other template features can optimize for that parameter: 
show sdm prefer { access | default | dual-ipv4-and-ipv6 | routing | vlan }.
Another common reason for changing the SDM template is because you are running out of a specific resource. 
For example, the use of the switch in a large Layer 2 domain with many ACLs may require a change to the access SDM template. 
System Resource Configuration on Other Platforms
SDM templates configure the switch for specific allocation of finite resources.
The use of SDM templates is summarized as follows:
To verify the amount of resources being used, use the command show platform tcam utilization.
To verify the SDM template that is currently in use, use the command show sdm prefer.
To change the template to dual stack, use the command sdm prefer dual-ipv4-and-ipv6 default.
When changing the SDM template, a reload of the switch is required.

Monitoring Features
Upon completing this lesson, you will be able to meet these objectives:
Describe SPAN
Describe SPAN terminology
Describe different versions of SPAN
Configure SPAN
Verify local SPAN configuration
Configure RSPAN
Verify RSPAN configuration
SPAN and RSPAN Overview
SPAN session: An association of a destination port with source ports.
Source VLAN: VLAN monitored for traffic analysis.
SPAN Terminology
Remote SPAN Overview
Remote SPAN supports source and destination ports on different switches, while local SPAN supports only source and destination ports on the same switch.
RSPAN
In terms of configuration, RSPAN consists of the following:
RSPAN source session
RSPAN VLAN
RSPAN destination session
SPAN Configuration
SPAN adheres to the following caveats
A destination port cannot be a source port or vice versa.
The number of destination ports is platform dependent; some platforms allow for more than one destination.
Destination ports do not act as normal ports and do not participate in spanning tree and so on. Normal traffic flows through a destination. Be careful not to connect anything besides an end device to a SPAN destination port.
SPAN Configuration
RSPAN Configuration
SW1(config)# vlan 100
SW1(config-vlan)# name RSPAN-VLAN
SW1(config-vlan)# remote-span
SW1(config-vlan)# exit
SW1(config)# monitor session 2 source interface Giga0/1
SW1(config)# monitor session 2 destination remote vlan 100
RSPAN Configuration
SW2(config)# vlan 100
SW2(config-vlan)# name RSPAN-VLAN
SW2(config-vlan)# remote-span
SW2(config-vlan)# exit
SW2(config)# monitor session 2 destination interface Giga 0/2
SW2(config)# monitor session 2 source remote vlan 100
RSPAN Verification

IP SLA
Upon completion of this section, you will understand the following:
Basic use cases of IP SLA
What an IP SLA source and responder are
Basic example of an ICMP IP SLA configuration and a UDP configuration
Introduction to IP SLA
An SLA (service level agreement) is a contract between the network provider and its customers, or between a network department and internal corporate customers. It provides a form of guarantee to customers about the level of user experience.
SLA may contain specifics about connectivity and performance agreements for an enduser service from a service provider. 
An SLA typically outlines the minimum level of service and the expected level of service. 
Introduction to IP SLA
An SLA can also be used as the basis for planning budgets and justifying network expenditures.
Overall, the IP SLA feature provides real-time feedback about network reachability. For features such as voice and video, network availability with stable jitter and latency are important. 
The IP SLA provides the feedback necessary to ensure the network can sustain real-time applications as well as mission-critical applications such as web portal or ordering. 
IP SLA Additional Uses
Additional functions and uses for IP SLA are as follows:
Edge-to-edge network availability monitoring.
Network performance monitoring and network performance visibility
Voice over IP (VoIP), video, and virtual private network (VPN) monitoring
SLA monitoring
IP service network health
MPLS network monitoring
Troubleshooting of network operation

IP SLA Options
Switch(config-ip-sla)# ?
IP SLAs entry configuration commands:
	dhcp 		DHCP Operation
	dns 		DNS Query Operation
	exit 		Exit Operation Configuration
	ftp 		FTP Operation
	http 		HTTP Operation
	icmp-echo 	ICMP Echo Operation
	path-echo 	Path Discovered ICMP Echo Operation
	path-jitter 	Path Discovered ICMP Jitter Operation
	tcp-connect 	TCP Connect Operation
	udp-echo 	UDP Echo Operation
	udp-jitter 	UDP Jitter Operation
IP SLA Source and Responder
The source is the Cisco IOS device that sends probe packets. 
The destination of the probe may be another Cisco device or another network target such as a web server or IP host.
Although the destination of the majority of the tests can be any IP device, the measurement accuracy of some of the tests can be improved with an IP SLA responder. 
An IP SLA responder is a device that runs Cisco IOS Software. 
The responder adds a time stamp to the packets sent so the IP SLA source can take into account any latency that occurred while the responder is processing the test packets. 
For this test to work properly, both the source and responder clocks need to be synchronized through Network Time Protocol (NTP).
IP SLA Configuration
To implement IP SLA network performance measurement, you need to perform the following tasks:
Step 1. Enable the IP SLAs responder, if required.
Step 2. Configure the required IP SLA’s operation type.
Step 3. Configure any options available for the specified operation type.
Step 4. Configure threshold conditions, if required.
Step 5. Schedule the operation to run, and then let the operation run for a period of time to gather statistics.
Step 6. Display and interpret the results of the operation using the Cisco IOS CLI or a network management system (NMS) with SNMP.
IP SLA ICMP Echo Confi guration Example
Verify IP SLA Configuration
Verify IP SLA Configuration
IP SLA Operation with Responder
IP SLA Time Stamps
T1 time is marked from 0 in milliseconds for simplicity. 
The RTT in this example is calculated as 
RTT = T5 – (T5-T4) - (T3-T2) = 1.5msec – (1.5msec-1.3msec) – (0.7msec - 0.5msec) = 1.1msec .
Configuring Authentication for IP SLA
IP SLA UDP Jitter Example
Chapter 8 Summary
LLDP and the legacy CDP features are useful for discovering neighbor adjacencies and their details.
The UDLD aggressive mode feature is useful in adding resiliency to networks to avoid disasters in case of anomalous behaviors.
SPAN and RSPAN are common debugging and traffic capture features that are also leveraged to capture traffic for network analytics.
The IP SLA
Chapter 8 Labs
CCNPv7.1 SWITCH Lab8.1 IP SLA SPAN

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva8

High Availability
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 9 Objectives
This chapter covers the following Cisco Catalyst switch features:
The need and basic idea behind switch stacking and VSS
StackWise
The benefits of StackWise
Verifying StackWise
VSS
VSS benefits
Verifying VSS
Supervisor redundancy
Supervisor redundancy modes
The Need for Logical Switching Architectures
The Need for Logical Switching Architectures
Access switchs needs its own uplink to each of the distribution switches to satisfy the redundancy requirements, but one of the uplinks has to be blocked by the Spanning Tree Protocol (STP) to prevent a loop, thus cutting the bandwidth in half.
To overcome some of these limitations, Cisco proposes the following virtualization solutions.
StackWise: Focused on the access layer module
VSS: Focused on the aggregation layer module

What Is StackWise?
Cisco StackWise technology provides a method for collectively utilizing the capabilities of a stack of switches. 
Configuration and routing information is shared by every switch in the stack, creating a single switching unit. 
Switches can be added to and deleted from a working stack without affecting performance.





The stack is managed as a single unit by a master switch, which is elected from one of the stack member switches.
StackWise Details
Each stack of switches has a single IP address and is managed as a single object. 
This allows each switch in the stack to share the same network topology, MAC address, and routing information.
Catalyst 3750-E, 3750-X, and 3850 series switches support StackWise and StackWise Plus. 
StackWise Plus is an evolution of StackWise. StackWise Plus supports local switching, so locally destined packets need not traverse the stack ring. 
Catalyst 3850 series supports StackWise-480 with improved 480-Gbps stacking. Catalyst 2960-S series supports FlexStack, aStackWise-based feature tailored for Layer 2 switches. FlexStack is limited to four stacked switches.
StackWise Benefits
Verifying StackWise

What Is VSS?
Virtual Switching System (VSS) is a network system virtualization technology that combines a pair of Catalyst 4500 or 6500 series switches into one virtual switch, increasing the operational efficiency, boosting nonstop communications, and scaling the system bandwidth capacity.
The VSS simplifies network configuration and operation by reducing the number of Layer 3 routing neighbors and by providing a loop-free Layer 2 topology.

What Is VSS?
The VSL is made of up to eight 10 Gigabit Ethernet connections bundled into an EtherChannel. 
VSL carries the control plane communication between the two VSS members, in addition to regular data traffic.
Once the VSS is formed, only the control plane of one of the members is active. The data plane and switch fabric of both members are active.
Both chassis are kept in sync with the interchassis SSO mechanism, along with NSF to provide nonstop communication even in the event of failure of one of the member supervisor engines or chassis. 
VSS Benefits
VSS increases operational efficiency by reducing switch management overhead and simplifying the network. 
It provides a single point of management, IP address, and routing instance.
Neighbors see the VSS as a single Layer 2 switching or Layer 3 routing node, thus reducing the control protocol traffic. 
VSS provides a single VLAN gateway IP address, removing the need for the first-hop redundancy protocol (HSRP, VRRP, GLBP),
Multichannel EtherChannel (MEC) allows you to bundle links to two physical switches in VSS, creating a loop-free redundant topology without the need for STP.
Interchassis stateful failover results in no disruption to applications that rely on network state information. 
VSS eliminates Layer 2 / Layer 3 protocol reconvergence if a virtual switch member fails, resulting in deterministic subsecond virtual switch recovery.
VSS Benefits
Verifying VSS
To verify the status of VSS configuration, use the following commands:
show switch virtual
show switch virtual link
show switch virtual role
show switch virtual link port-channel
Verifying VSL
Redundant Switch Supervisors
Redundant Switch Supervisors
The Cisco supervisor engine module is the heart of the Cisco modular switch platforms.
The supervisor provides centralized forwarding information and processing. 
All software processes of a modular switch are run on a supervisor.
Redundant supervisors are highly recommended for the aggregation and core layer so that they might help provide faster convergence in case of the primary supervisor failure. Platforms such as the Catalyst 4500, 6500, and 6800 series can accept two supervisor modules that are installed in a single chassis, thus removing a single point of failure. 
The first supervisor module to successfully boot becomes the active supervisor for the chassis.
The other supervisor remains in a standby role, waiting for the active supervisor to fail.
The active supervisor provides all switching functions. The standby supervisor, however, is allowed to boot and initialize only to a certain level. 
When the active module fails, the standby module can proceed to initialize any remaining functions and take over the active role.
Supervisor Redundancy Modes
Redundant supervisor modules can be configured in several modes.
Redundancy mode limits the standby supervisor’s state of readiness.
SSO allows for NSF.
Supervisor Redundancy Modes
Route processor redundancy (RPR)
The redundant supervisor is only partially booted and initialized. When the active module fails, the standby module must reload every other module in the switch and then initialize all the supervisor functions.
Route processor redundancy plus (RPR+)
The redundant supervisor is booted, allowing the supervisor and route engine to initialize. No Layer 2 or Layer 3 functions are started. When the active module fails, the standby module finishes initializing without reloading other switch modules. This allows switch ports to retain their state.
Stateful switchover (SSO)
The redundant supervisor is fully booted and initialized. Both the startup and running configuration contents are synchronized between the supervisor modules. Layer 2 information is maintained on both supervisors so that hardware switching can continue during a failover. The state of the switch interfaces is also maintained on both supervisors so that links do not flap during a failover.
Stateful Switchover
The redundant supervisor engine starts up in a fully initialized state and synchronizes with the startup configuration and the running configuration of the active supervisor engine. 
The standby supervisor in SSO mode also keeps in sync with the active supervisor engine for all changes in hardware and software states for features that are supported via SSO. 
Any supported feature interrupted by failure of the active supervisor engine is continued seamlessly on the redundant supervisor engine.
Nonstop Forwarding
NSF is an interactive method that focuses on quickly rebuilding the Routing Information Base (RIB) table after a supervisor switchover. 
The RIB is used to generate the Forwarding Information Base (FIB) table for CEF, which is downloaded to any switch modules that can perform CEF.
NSF with SSO redundancy includes the standard SSO for Layer 2 switching; however, it also minimizes the amount of time that a Layer 3 network is unavailable following a supervisor engine switchover by continuing to forward IP packets using CEF entries built from the old active supervisor.
Chapter 9 Summary
The need and basic idea behind switch stacking and VSS
StackWise
The benefits of StackWise
Verifying StackWise
VSS
VSS benefits
Verifying VSS
Supervisor redundancy
Supervisor redundancy modes

Chapter 9 Labs
None

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva

Campus Network Security
CCNP  SWITCH: Implementing Cisco IP Switched Networks
Chapter 10 Objectives
This chapter covers the following topics:
Overview of switch security issues
Required best practices for basic security protection on Catalyst switches
Campus network vulnerabilities
Port security
Storm control
Mitigating spoofing attacks
DHCP snooping, IP Source Guard, and dynamic ARP inspection
Securing VLAN trunks
Private VLANs
Overview of Switch Security Issues
Overview of Switch Security Issues
Most of the industry attention focuses on security attacks from outside the walls of an organization and at the upper OSI layers.
The default state of networking equipment highlights this focus on external protection and internal open communication.
Many security features are available for switches and routers, but they must be enabled to be effective
Overview of Switch Security Issues
Reasons exist for strong protection of the enterprise campus infrastructure
Relying on the security that has been established at the enterprise edge fails as soon as security there is compromised. Having several layers of security increases the protection of the enterprise campus, where the most strategic assets usually reside.
If the enterprise allows visitors into its buildings, an attacker can potentially gain physical access to devices in the enterprise campus. Relying on physical security is not enough.
Very often, external access does not stop at the enterprise edge. Applications require at least an indirect access to the enterprise campus resources, which means that strong campus network security is also necessary.
Public and hybrid cloud architectures pose new risks. Even if the cloud is secure, attacks from the inside can ultimately compromise the cloud.

Cisco Switch Security Configuration Best Practices
Secure passwords
The enable password command employs weak encryption.
Use enable secret whenever possible.
Use the service password-encryption global configuration command to encrypt all passwords that cannot be encrypted using strong authentication. 
Having external AAA.
Leverage system banners
The goal is to warn unauthorized users that their activities could be grounds for persecution.
Use the banner login command.
Secure console access
Even though switches usually reside in locked cabinets and access-controlled data centers, it is a best practice to configure authentication on any console. 
Cisco Switch Security Configuration Best Practices
Secure vty access 
Always secure all vty lines on a device.
Configure access lists to limit access from source IP addresses of potential administrative users who try to access the device remotely.
access-list 1 permit 10.0.0.234
access-list 1 permit 10.0.0.235
line vty 0 15
access-class 1 in
Secure the embedded web interface
If you are not using web interface to manage a switch, disable its web interface using no ip http server command.
If you do decide to use the switch’s web interface, use HTTPS. To enable HTTPS, use the ip http secure server global configuration command.
If you do decide to use the switch’s web interface, use access lists to limit source addresses that can access the HTTPS interface.
access-list 1 permit 10.100.50.0 0.0.0.255
ip http secure server
ip http access-class 1
Cisco Switch Security Configuration Best Practices
Always leverage Secure Shell (SSH) and ensure that the Telnet server is disabled
Telnet is easy to use but not secure. All text that is sent through a Telnet session is passed in clear text. 
SSH uses strong encryption to secure session data. You should use the highest SSH version available on the device.
Secure SNMP access 
If you do not need the write access through SNMP, disable it.
It is always recommended to exclusively use SNMPv3, which leverages secure authentication.
Cisco Switch Security Configuration Best Practices
Secure STP operation 
You should always enable the BPDU Guard feature on any access switch ports. 
Do not ever configure BPDU Guard and BPDU Filter on the same port. If you do, only BPDU Filter will take effect. 
Secure Cisco Discovery Protocol (CDP)
As a rule, all Cisco devices have CDP enabled on all ports by default. Disable CDP on ports that connect to outside networks.
In addition, always disable CDP on end-user access ports.
CDP advertisements are sent in clear text, and you cannot configure authentication. 
Cisco Switch Security Configuration Best Practices
Secure unused switch ports
All unused switch ports should be shut down to prevent unauthorized users from connecting to your network.
All user ports should be configured with switchport mode access command. 
Place all unused ports into an isolated or bogus VLAN. 

Rogue Access
Rogue access comes in several forms. 
These rogue devices can be a serious breach of network security because they can be plugged into a network port behind the corporate firewall. 
Because employees generally do not enable any security settings on the rogue AP, it is easy for unauthorized users to use the AP to intercept network traffic and hijack client sessions.
Switch Vulnerabilities
Attacks that are launched against switches and at Layer 2 can be grouped as follows:
MAC layer attacks
VLAN attacks
Spoofing attacks
Attacks on switch devices
MAC Layer Attacks
MAC Address Flooding
Frames with unique, invalid source MAC addresses flood the switch, exhausting the content-addressable memory (CAM) table space, disallowing new entries from valid hosts. 
Traffic to valid hosts is then flooded out all ports.
Mitigation
Port security.
MAC address VLAN access maps.
VLAN Attacks
VLAN Hopping
By altering the VLAN ID on packets that are encapsulated for trunking, an attacking device can send packets on various VLANs, bypassing Layer 3 security measures.
Mitigation
Tighten up trunk configurations and the negotiation state of unused ports. Shut down unused ports. Place unused ports in a common VLAN.
Attacks Between Devices on a Common VLAN
Devices may need protection from one another, even though they are on a common VLAN. This is especially true o service provider segments that support devices from multiple customers.
Mitigation
Implement private VLANs (PVLANs).
Spoofing Attacks
DHCP Starvation and DHCP Spoofing
An attacking device can exhaust the address space available to the DHCP servers for a time period or establish itself as a DHCP server in man-in-the-middle attacks.
Mitigation
Use DHCP snooping.
Spanning-tree Compromises
Attacking device spoofs the root bridge in the Spanning Tree Protocol (STP) topology. If successful, the network attacker can see various frames.
Mitigation
Proactively configure the primary and backup root devices. 
Enable Root Guard.
Spoofing Attacks
MAC Spoofing
Attacking device spoofs the MAC address of a valid host currently in the CAM table. The switch then forwards to the attacking device any frames that are destined for the valid host.
Mitigation 
Use DHCP snooping, port security.
Address Resolution Protocol (ARP) spoofing
Attacking device crafts Address Resolution Protocol (ARP) replies intended for valid hosts. The MAC address of the attacking device then becomes the destination address that is found in the Layer 2 frames that were sent by the valid network device.
Mitigation
Use DAI.
Use DHCP snooping, port security.
Switch Device Attacks
Cisco Discovery Protocol (CDP manipulation)
Information sent through CDP is transmitted in clear text and unauthenticated, allowing it to be captured and to divulge network topology information.
Mitigation 
Disable Cisco Discovery Protocol on all ports where it is not intentionally used.
SSH Protocol and Telnet Attacks
Telnet packets can be read in clear text. SSH is an option, but it has security issues in Version 1.
Mitigation
Use SSH Version 2. 
Use Telnet with vty ACLs.
Introducing Port Security
Introducing Port Security
Port security restricts a switch port to a specific set or number of MAC addresses.
Those addresses can be learned dynamically or configured statically. 
The port will then provide access to frames from only those addresses. 
Port Security Process
1. Configure port security.
Configure port security to allow only the desired number of connections on the port. 
Configure an entry for each of these allowed MAC addresses. 
This configuration, in effect, populates the MAC address table with new entries for that port and allows no additional entries to be learned dynamically.
2. Allowed frames are processed.
When frames arrive on the switch port, their source MAC address is checked against the MAC address table. If the frame source MAC address matches an entry in the table for that port, the frames are forwarded to the switch to be processed like any other frames on the switch.
Port Security Process (cont)
3. New addresses are not allowed to create new MAC address table entries.
When frames with a nonallowed MAC address arrive on the port, the switch determines that the address is not in the current MAC address table and does not create a dynamic entry for that new MAC address, because the number of allowed addresses has been limited.
4. Switch takes action in response to nonallowed frames.
The switch will disallow access to the port and take one of these configuration-dependent actions: the entire switch port can be disabled, access can be denied for that MAC address only and a log error can be generated, or access can be denied for that MAC address but without generating a log message.
Port Security Configuration
switchport port-security maximum value
Optionally sets the maximum number of secure MAC addresses for the interface. The range is 1 to 3072; the default is 1.
switchport port-security violation { restrict | shutdown }
Optionally sets the violation mode, the action to be taken when a security violation is detected, as one of these: 
restrict A port security violation restricts data and causes the SecurityViolation counter to increment and send an SNMP trap notification.
shutdown The interface is err-disabled when a portsecurity violation occurs.
switchport port-security limit rate invalid-source-mac
Sets the rate limit for bad packets.

Port Security Configuration (cont)
switchport port-security mac-address mac-address
Optionally enters a secure MAC address for the interface.
You can use this command to enter the maximum number of secure MAC addresses. If you configure fewer secure MAC addresses than the maximum, the remaining MAC addresses are dynamically learned.
switchport port-security mac-address sticky
Optionally enables sticky learning on the interface.

Port Security Example
Port Security Example II
Port Error Conditions
The following list highlights the most common situations where a port will go into the err-disabled state:
Port security violation
When an invalid MAC address is learned on a port or too many MAC addresses, the switch can optionally place the port into the err-disabled state.
Spanning-tree BPDU guard violation
When you have PortFast configured in combination with BPDU Guard
EtherChannel misconfiguration
All parameters have to be the same for all ports on both sides of the bundle
Duplex mismatch
Duplex mode has to be the same on both sides of the link;
Port Error Conditions (cont)
UDLD condition
Unidirectional Link Detection (UDLD) ensures that the link is bidirectional at all times; so when it detects a unidirectional link, it places the port into the err-disabled state.
Spanning-tree Root Guard
If a Root Guard-enabled port receives a superior BPDU from those sent by the current root bridge
Link flapping
When link state is flapping between the up and down states, the port is placed into the err-disabled state.
Other reasons
Other reasons include late collision detection, Layer 2 Tunneling Protocol Guard, DHCP snooping rate-limit, incorrect gigabit interface convert (GBIC), and ARP inspection.
Err-Disable Ports
Err-disabled detection is enabled for all of these causes by default. 
You can configure other reasons to trigger the port being disabled. 
Use the following command to specify the causes:

Switch(config)# errdisable detect cause [ all | cause-name ]
Err-Disabled Automatic Recovery
Once the root cause of the err-disabled state is removed, an err-disabled port can become operational after a shut / no shut. 
Because the error condition is no longer present, the trigger for err-disable will not occur. 
Therefore, to reduce the administrative overhead, the switch port can be configured to be automatically reenabled after a specified time. 
Of course, if the error condition is still present, the port will immediately go back to the err-disabled state.
Port Access Lists
Port access lists (PACLs) are yet another way to apply security in the campus network.
Standard access control lists (ACLs) are applied to traffic passing through the Layer 3 interface. 
The PACL feature provides the ability to perform access control on a specific Layer 2 port.
A Layer 2 port is a physical access or trunk port that belongs to a VLAN. 
The port ACL feature is supported only in hardware. (Port ACLs are not applied to any packets routed in software.) 
The PACL feature does not affect Layer 2 control packets, such as CDP, VTP, DTP, and STP, received on the port.
Port Access Lists
There are two types of PACL:
IP access list 
Filters IPv4 and IPv6 packets on a Layer 2 port.
MAC access list 
Filters packets that are of an unsupported type (not IP, ARP, or MPLS) based on the fields of the Ethernet frame. 
A MAC access list is not applied to IP, MPLS, or ARP messages. 
You can define only named MAC access lists.
Port Access Lists
PACLs interaction with other types of ACLs depends on the configured mode:
In prefer port mode , the PACL takes effect and overrides the effect of other ACLs. This mode is the only mode that is allowed when applying PACL on a trunk.
In merge mode , PACLs, VACLs, and standard ACLs are merged in the ingress direction. This is the default mode.
IP and MAC ACLs can be applied to Layer 2 physical interfaces. Standard (numbered, named) and extended (numbered, named) IP ACLs and extended named MAC ACLs are supported.
Port Access Lists
Commands to configure a MAC ACL and apply it to a Layer 2 interface:
SW(config)# mac access-list extended acl-name
SW(config-ext-macl)# permit host [ source-mac | any ] [ destination-mac | any ]
SW(config-ext-macl)# interface interface-slot/number
SW(config-if)# mac access-group acl-name in

Commands to configure an IP ACL and apply it to a Layer 2 interface:
SW(config)# ip access-list acl-type acl-name
SW(config-ext-nacl)# permit protocol [ source-address | any ] [ destination-address | any ]
SW(config-ext-nacl)# interface interface-slot/number
SW(config-if)# ip access-group acl-name in
PACL’s Group Mode
Configure the access group mode on a Layer 2 interface:
SW(config)# interface interface-slot/number
SW(config-if)# access-group mode [ prefer port | merge ]

Note:  
Access mode command is not supported on all platforms.

Storm Control
Describe what a traffic storm is and how to control it
Configure and verify storm control
Introduction to Storm Control
A traffic storm occurs when packets flood the LAN, creating excessive traffic and degrading network performance.
The storm control feature prevents LAN ports from being disrupted by a broadcast, multicast, or unicast traffic storm on physical interfaces.
Storm Control Behavior
During the interval, it compares the traffic level with the traffic storm threshold level that you configure. 
The traffic storm control level is either an absolute number of bits or packets per second or a percentage of the total available bandwidth of the port. 
Two thresholds can be configured. 
When traffic exceeds the rising threshold level, storm control blocks the port. 
Once the traffic falls under the falling threshold, storm control removes the block. 
Configuration of a falling threshold is optional.

Storm Control Behavior
Optionally, an interface can be shut down if a threshold level is breached or an SNMP trap is sent. 
In addition, storm control is configured per interface for each traffic type (unicast, multicast, broadcast) separately. 
Configuring and Verifying Storm Control on an Interface
Switch(config)# interface interface-slot/int
Switch(config-if)# storm-control [ broadcast | multicast | unicast ] level { risingpercent | bps rising-bps | pps rising-pps } [falling-percent|falling-bps|falling-pps]
Switch(config)# interface interface-slot/int
Switch(config-if)# storm-control action { shutdown|trap }
Verify Storm Control Configurations

Mitigating Spoofing Attacks
How can a rogue DHCP server harm your network
DHCP spoofing
Configuring and verifying DHCP snooping
What IP Source Guard is and why you need it
Configuring IP Source Guard
ARP spoofing
How DAI works
Configure DAI
DHCP Spoofing Attacks
The most common example of a rogue DHCP server is when a PC is configured as a DHCP server in the campus network.
If the rogue DHCP server’s reply arrives at the DHCP client first, the client will use this response. 
Because this first response from the rogue server is bogus, the client will not be able to gain the correct network connectivity and may have its traffic redirected to a bogus default gateway
Rogue DHCP Server Process
Attacker hosts a rogue DHCP server off a switch port to the same subnet as the clients.
Client broadcasts a request for DHCP configuration information.
The rogue DHCP server responds before the legitimate DHCP server, assigning attacker-defined IP configuration information.
Host packets are redirected to the attacker’s address because it emulates a default gateway for the erroneous IP address that is provided to the client via DHCP.
DHCP Snooping
DHCP Snooping feature configures two types of port:
Trusted ports 
Host a DHCP server or can be an uplink toward the DHCP server.
Untrusted ports
Are those that are not explicitly configured as trusted. 
From a DHCP snooping perspective, untrusted access ports should not send any DHCP server responses, such as DHCPOFFER, DHCPACK, or DHCPNAK. 
If a rogue device on an untrusted port attempts to send a DHCP response packet into the network, the port is shut down. 
This feature can be coupled with DHCP option 82, in which switch information, such as the port ID of the DHCP request, can be inserted into the DHCP request packet.
DHCP Snooping
DHCP Snooping Example Configuration
DHCP Snooping Example Configuration
Steps to enable DHCP snooping for VLAN 10 with a DHCP server on Ethernet 0/0:
Step 1. Enable DHCP snooping globally.
Step 2. Enable DHCP snooping on selected VLANs.
Step 3. Configure trusted interfaces, since untrusted is default.
Step 4. Configure rate-limit of DHCP requests on untrusted ports.
Step 5. Configure information option using DHCP option 82.
Verifying DHCP Snooping Configuration
Verifying DHCP Snooping Configuration
DHCP Snooping Command Review
ip dhcp snooping 
Enables DHCP snooping globally. By default, the feature is not enabled.
ip dhcp snooping information option
Enables DHCP option 82. This is optional for the forwarded DHCP request packet to contain information on the switch port where it originated. The option is enabled by default.
ip dhcp snooping vlan vlan-id [ vlan-id ]
Identifies VLANs that will be subject to DHCP snooping.
ip dhcp snooping trust 
Configures trusted port. Use the no keyword to revert to untrusted. Use this command in the interface configuration mode.
ip dhcp snooping limit rate rate
Configures the number of DHCP packets per second that an interface can receive. This ensures that DHCP traffic will not overwhelm the DHCP servers. Normally, the rate limit applies to untrusted interfaces. Use this command in the interface configuration mode.
show ip dhcp snooping 
Verifies the configuration.
IP Source Guard
IPSG operates by dynamically maintaining per-port VLAN ACLs based on learned IP-to-MAC-to-switch-port bindings.
When IPSG is enabled, the switch blocks all IP traffic into the port except for DHCP packets captured by the DHCP snooping process.
After the DHCP process is complete and the client receives a valid IP address from the DHCP server (or when a static IP source binding is configured by the user), a per-port and VLAN access control list (PVACL) is installed on the port dynamically.
This process restricts the client IP traffic ingress on the respective port to the source IP address that is configured in the binding. 
Any IP traffic with a source IP address other than that in the IP source binding will be filtered out. 
IPSG Topology Layout
IPSG Filters
For each untrusted port, there are two possible levels of IP traffic security filtering:
Source IP address filter
IP traffic is filtered based on its source IP address. Only IP traffic with a source IP address that matches the IP source binding entry is permitted. An IP source address filter is changed when a new IP source entry binding is created or deleted on the port. 
Source IP and MAC address filter
IP traffic is filtered based on its source IP address in addition to its MAC address; only IP traffic with source IP and MAC addresses that match the IP source binding entry are permitted.
IPSG Configuration
IPSG Configuration
To enable IPSG on the port use the ip verify source interface command for enabling IP address filters. 
To enable MAC address filtering and IP filters, add the ip verify source port-security interface command.
IPSG Configuration and State Verification
ARP Spoofing
ARP Spoofing
Step 1. PCA sends an ARP request for MAC address of R1.
Step 2. R1 replies with its MAC and IP address. It also updates its ARP cache.
Step 3. PCA binds MAC address of R1 to R1’s IP address in its ARP cache.
Step 4. Attacker sends its ARP reply to PCA, binding its MAC address to the IP of R1.
Step 5. PCA updates ARP cache with MAC address of attacker bound to IP address of R1.
Step 6. Attacker sends its ARP reply to R1, binding its MAC address to the IP of PCA.
Step 7. R1 updates ARP cache with MAC address of attacker bound to IP address of PCA.
Step 8. Packets are diverted through attacker.
Dynamic ARP Inspection
Dynamic ARP inspection (DAI) helps prevent such attacks by not relaying invalid or gratuitous ARP replies out to other ports in the same VLAN. 
DAI intercepts all ARP requests and all replies on the untrusted ports. 
Each intercepted packet is verified for valid IP-to-MAC binding similar to IPSG.
ARP replies coming from invalid devices are either dropped or logged by the switch for auditing so that ARP poisoning attacks are prevented.
You can also use DAI to rate-limit the ARP packets and then err-disable the interface if the rate is exceeded. 
DAI determines the validity of an ARP packet based on a valid MAC-address-to-Ip address bindings database that is built by DHCP snooping. 
In addition, to handle hosts that use statically configured IP addresses, DAI can validate ARP packets against user configured ARP ACLs.
DAI Configuration Steps
Step 1. Implement protection against DHCP spoofing:
a. Enable DHCP snooping globally.
b. Enable DHCP snooping on selected VLANs.
Step 2. Enable DAI: Enable ARP inspection on selected VLANs.
Step 3. Configure trusted interfaces for DHCP snooping and ARP inspection (untrusted is default).
DAI Configuration
DAI Commands
ip arp inspection vlan vlan-id [ , vlan-id ] 
Enables DAI on a VLAN or range of VLANs
ip arp inspection trust 
Sets the interface as a trusted interface
ip arp inspection validate {[ src-mac ] [ dst-mac ] [ ip ]}
Configures DAI to drop ARP packets when the IP addresses are invalid, or when the MAC addresses in the body of the ARP packets do not match the addresses that are specified in the Ethernet header

Securing VLAN Trunks
Describe the switch spoofing attack associated with VLAN trunks
Protect your network against switch spoofing
Describe the VLAN hopping attack
Protect your network against the VLAN hopping attack
Describe the need for VLAN access lists
Describe how VLAN access lists interact with standard and port access lists
Configure the VLAN access lists
Switch Spoofing
There are several mechanisms or best practices to minimize authorized access to trunk ports and switch spoofing, including the following
Manually configure access and trunk ports
Shut down unused interfaces
Restrict VLANs on trunk ports
Switch Spoofing
VLAN Hopping
The IP-enabled device the attacker is using must be connected to an access port.
The IP-enabled device must send a double-tagged frame.
The first-hop switch must be configured to accept 802.1Q frames.
The first-hop switch must be connected to another switch with an 802.1Q truck, and its native VLAN must match the attackers outer VLAN tag.
Protecting Against VLAN Hopping
Because an attacker’s port VLAN must match the native VLAN of a trunk, the simple solution is to configure the native VLAN of all trunk ports to an unused VLAN.
SW(config)# interface interface-slot/number
SW(config-if)# switchport trunk native vlan vlan-id
SW(config-if)# switchport trunk allowed vlan remove vlan-id

Yet another option is to tag all frames on trunk ports by default. The command to configure this option is as follows:
SW(config)# vlan dot1q tag native
VLAN Access Lists
VACLs can provide access control for all packets that are bridged within a VLAN or packets that are routed into or out of a VLAN or a WAN interface.
VACLs can configured for IP or MAC layer traffic with some limitations depending on platform and software version.
VLAN access lists (VACLs) on Catalyst switches serve the following two distinct purposes:
With certain limitations, filter traffic at Layer 2
Overcome VLAN Switch Port Analyzer (SPAN) limitations via use of the Capture Port feature
VACLs Process	
Each VLAN access map can consist of one or more map sequences; each sequence has a match clause and an action clause. 
The match clause specifies IP or MAC ACLs for traffic filtering, and the action clause specifies the action to be taken when a match occurs.
When a flow matches a permit ACL entry, the associated action is taken, and the flow is not checked against the remaining sequences. 
When a flow matches a deny ACL entry, it will be checked against the next ACL in the same sequence or the next sequence. 
If a flow does not match any ACL entry and at least one ACL is configured for that packet type, the packet is denied.
Advantage of VACL Capture Port usage over VSPAN
Granular traffic analysis	
VACLs can match based on source IP address, destination IP address, Layer 4 protocol type, source and destination Layer 4 ports, and other information.
The number of sessions
VACLs are enforced in hardware..
Destination port oversubscription
Granular traffic identification reduces the number of frames to be forwarded to the destination port and thereby minimizes the probability of their oversubscription.
VACLs are enforced in hardware
VACL Interaction with ACLs and PACLs
Configuring VACLs
SW(config)# mac access-list extended acl-name
SW(config-ext-macl)# permit host [ source-mac | any ] [ destination-mac | any ]
SW(config)# ip access-list acl-type acl-name
SW(config-ext-nacl)# permit protocol [ source-address | any ] [ destination-address | any ]

SW(config)# vlan access-map map-name
SW(config-access-map)# match [ mac | ip ] address acl-name
SW(config-access-map)# action [drop|forward|redirect][log]

SW(config)# vlan filter map-name vlan-list [ vlan-list | all ]

VACL examples
Private VLANs
Private VLANs
Introduction to private VLANs
Describe the private VLAN feature
Describe the private VLAN port types
Configure private VLANs
Verify private VLAN configuration
Describe private VLANs across multiple switches
Describe the protected port feature
Introduction to PVLANs
PVLANs restrict enduser devices such as PCs and mobile devices from communicating with each other, but still allow communication to router ports and network services. 
The end-user devices will behave as normal but cannot communicate to other devices in the same Layer 2 domain. 
This mechanism provides a level of security.
Assigning every single end device its own VLAN would accomplish the same security method as PVLANs; however, switches have a limit on the number of VLANs supported, and a large number of VLANs creates scalability issues.
Introduction to PVLANs
PVLANs are essentially VLANs inside a VLAN. 
A Layer 3 device is needed to route packets between different PVLANs. 
When a VLAN is partitioned into PVLANs, devices in different PVLANs still belong to the same IP subnet, but are unable to communicate with each other on Layer 2.
PVLANs are an elegant solution when you need to keep multiple devices in the same IP subnet yet provide port isolation on Layer 2. 
Introduction to PVLANs
PVLAN Port Types
A PVLAN domain has one primary VLAN. 
Each port in a private VLAN domain is a member of the primary VLAN; the primary VLAN is the entire private VLAN domain.
Secondary VLANs are subdomains that provide isolation between ports within the same private VLAN domain. 
There are two types of secondary VLANs: isolated VLANs and community VLANs. 
Isolated VLANs contain isolated ports, which cannot communicate between each other in the isolated VLAN. 
Community VLANs contain community ports that can communicate between each other in the community VLAN.
PVLAN Port Types
PVLAN Port Types
Promiscuous
A promiscuous port belongs to the primary VLAN and can communicate with all mapped ports in the primary VLAN, including community and isolated ports. 
There can be multiple promiscuous ports in a primary VLAN.
Isolated
An isolated port is a host port that belongs to an isolated secondary VLAN. 
An isolated port has complete isolation from other ports, except with associated promiscuous ports. 
You can have more than one isolated port in a specified isolated VLAN. 
Community
A community port is a host port that belongs to a community secondary VLAN. 
Community ports communicate with other ports in the same community VLAN and with associated promiscuous ports. 
They are isolated from all ports in other community VLANs and all isolated ports.
PVLAN Configuration
VTP must be set to transparent or off.
Configure the primary VLAN.
Configure the secondary VLANs and apply the configuration of these PVLANs as isolated or community.
Associate the primary VLAN with the secondary VLANs

Assign Ports
Promiscuous Ports
SW(config)# interface interface-slot/number
SW(config-if)# switchport mode private-vlan promiscuous
SW(config-if)# switchport private-vlan mapping primary-vlan-id add secondary-vlanid {, secondary-vlan-id }

Community or Isolated Ports
SW(config)# interface range interface-range
SW(config-if-range)# switchport mode private-vlan host
SW(config-if-range)# switchport private-vlan host-association primary-vlan-id secondary-vlan-id
Assign Ports
Using the Protected Port Feature
The PVLAN feature is not available on all switches.
Protected port, also known as the PVLAN edge, is a feature that (unlike PVLANs) has only local significance to the switch. 
Protected ports do not forward any traffic to protected ports on the same switch.

SW(config)# interface interface-slot/number
SW(config-if)# switchport protected
Chapter 10 Summary
Configure port security to limit and filter MAC addresses on ports; port security supports features that reduce the overhead of assigning MAC addresses per port.
Use PVLANs to restrict traffic within a VLAN with simple configuration.
Leverage DHCP snooping, DAI, and IPSG to prevent spoofing attacks.
Consider VACLs when appropriate to block unnecessary traffic and known traffic attacks.
Always adhere to basic security configurations such as AAA on all Cisco devices.
Stay current on all vulnerabilities and security notices from Cisco.
Keep current on Cisco Catalyst software versions because new software versions address known vulnerabilities.
Chapter 10 Labs
CCNPv7.1 SWITCH Lab 10.1 Securing Layer2
CCNPv7.1 SWITCH Lab 10.2 Securing VLANs

Acknowledgment 
Some of the images and texts are from Implementing Cisco IP Switched Networks (SWITCH) Foundation Learning Guide: (CCNP SWITCH 300-115) by Richard Froom and Erum Frahim (1587206641) 
Copyright © 2015 – 2016 Cisco Systems, Inc.
Special Thanks to Bruno Silva10


